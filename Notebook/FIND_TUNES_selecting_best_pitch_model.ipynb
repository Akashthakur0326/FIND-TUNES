{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0pgWXpVZvkp",
        "outputId": "25a4cc0b-88d3-41e6-af03-2db618943a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing Dependencies...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "üéÆ HARDWARE STATUS: CUDA\n",
            "‚úÖ GPU Detected: Tesla T4\n",
            "\n",
            "üîÑ RENAMING MODELS...\n",
            "‚ÑπÔ∏è Already Renamed: OldCNN_NoSmooth.pth\n",
            "‚ÑπÔ∏è Already Renamed: OldCNN_Smooth.pth\n",
            "‚ÑπÔ∏è Already Renamed: OldCNN_Smooth_V2.pth\n",
            "‚ÑπÔ∏è Already Renamed: DeepCNN_NoSmooth.pth\n",
            "‚ÑπÔ∏è Already Renamed: DeepCNN_Smooth.pth\n",
            "‚ÑπÔ∏è Already Renamed: CRNN_NoSmooth.pth\n",
            "‚ÑπÔ∏è Already Renamed: CRNN_Smooth.pth\n",
            "\n",
            "üßπ Clearing old pitch directory...\n",
            "‚è© Audio directory already populated (1616 files). Skipping Unzip.\n",
            "‚úÖ Total Audio Files Ready: 1616\n",
            "\n",
            "üéµ Starting CREPE Pitch Extraction on 1616 files...\n",
            "   (Using GPU Resampling + Argmax Decoding for Speed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [41:57<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ SUCCESS: All 1616 pitch vectors saved to /content/all_pitch\n",
            "\n",
            "üì¶ Zipping 1616 files from /content/all_pitch...\n",
            "üöÄ Uploading to Drive: /content/drive/MyDrive/FIND_TUNE/processed_pitch_vectors_20260212_1454.zip ...\n",
            "‚úÖ SUCCESS! Data saved to: /content/drive/MyDrive/FIND_TUNE/processed_pitch_vectors_20260212_1454.zip\n",
            "   (File size: 150.28 MB)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP, DEPENDENCIES & GPU CHECK\n",
        "# ==============================================================================\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Install dependencies\n",
        "print(\"üì¶ Installing Dependencies...\")\n",
        "pkgs = [\"torchcrepe\", \"librosa\", \"torchaudio\", \"tqdm\"]\n",
        "for p in pkgs:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
        "\n",
        "import torch\n",
        "import torchcrepe\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- STRICT CUDA CHECK ---\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nüéÆ HARDWARE STATUS: {device.upper()}\")\n",
        "if device == 'cpu':\n",
        "    raise RuntimeError(\"‚ùå STOP! You are running on CPU. Go to Runtime > Change runtime type > Select T4 GPU.\")\n",
        "else:\n",
        "    print(f\"‚úÖ GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. MODEL RENAMING (Based on your Accuracy Table)\n",
        "# ==============================================================================\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/testing_models\"\n",
        "\n",
        "# Mapping: 'best (X).pth' -> 'New_Name.pth'\n",
        "mapping = {\n",
        "    \"best (15).pth\": \"OldCNN_NoSmooth.pth\",\n",
        "    \"best (16).pth\": \"OldCNN_Smooth.pth\",\n",
        "    \"best (17).pth\": \"OldCNN_Smooth_V2.pth\",\n",
        "    \"best (21).pth\": \"DeepCNN_NoSmooth.pth\",\n",
        "    \"best (18).pth\": \"DeepCNN_Smooth.pth\",\n",
        "    \"best (20).pth\": \"CRNN_NoSmooth.pth\",\n",
        "    \"best (19).pth\": \"CRNN_Smooth.pth\"\n",
        "}\n",
        "\n",
        "print(\"\\nüîÑ RENAMING MODELS...\")\n",
        "if os.path.exists(MODEL_DIR):\n",
        "    for old_name, new_name in mapping.items():\n",
        "        old_path = os.path.join(MODEL_DIR, old_name)\n",
        "        new_path = os.path.join(MODEL_DIR, new_name)\n",
        "\n",
        "        if os.path.exists(old_path):\n",
        "            os.rename(old_path, new_path)\n",
        "            print(f\"‚úÖ Renamed: {old_name} -> {new_name}\")\n",
        "        elif os.path.exists(new_path):\n",
        "            print(f\"‚ÑπÔ∏è Already Renamed: {new_name}\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è Not Found: {old_name}\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: Directory {MODEL_DIR} not found.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MEGA DATA EXTRACTION (SMART UNZIP)\n",
        "# ==============================================================================\n",
        "# Define paths\n",
        "ZIP_EVAL = \"/content/drive/MyDrive/FINE_TUNE_V3/eval_originals_300.zip\"\n",
        "ZIP_TRAIN = \"/content/drive/MyDrive/FINE_TUNE_V3/train_originals_1300.zip\"\n",
        "\n",
        "# Local temporary directories (Fast I/O)\n",
        "AUDIO_DIR = \"/content/all_audio\"\n",
        "PITCH_DIR = \"/content/all_pitch\"\n",
        "\n",
        "# --- SAFETY WIPE FOR PITCH ONLY ---\n",
        "# We wipe pitch to ensure fresh extraction, but check audio to save time\n",
        "print(f\"\\nüßπ Clearing old pitch directory...\")\n",
        "if os.path.exists(PITCH_DIR): shutil.rmtree(PITCH_DIR)\n",
        "os.makedirs(PITCH_DIR, exist_ok=True)\n",
        "\n",
        "# --- SMART UNZIP LOGIC ---\n",
        "# Only unzip if AUDIO_DIR is empty or doesn't exist\n",
        "if not os.path.exists(AUDIO_DIR) or len(os.listdir(AUDIO_DIR)) < 100:\n",
        "    print(f\"üìÇ Audio directory empty/missing. Unzipping FRESH data...\")\n",
        "    if os.path.exists(AUDIO_DIR): shutil.rmtree(AUDIO_DIR)\n",
        "    os.makedirs(AUDIO_DIR, exist_ok=True)\n",
        "\n",
        "    print(f\"   extracting Eval Set...\")\n",
        "    subprocess.run(f\"unzip -q -n '{ZIP_EVAL}' -d '{AUDIO_DIR}'\", shell=True)\n",
        "\n",
        "    print(f\"   extracting Train Set...\")\n",
        "    subprocess.run(f\"unzip -q -n '{ZIP_TRAIN}' -d '{AUDIO_DIR}'\", shell=True)\n",
        "else:\n",
        "    print(f\"‚è© Audio directory already populated ({len(os.listdir(AUDIO_DIR))} files). Skipping Unzip.\")\n",
        "\n",
        "# Check total files\n",
        "files = sorted(glob.glob(os.path.join(AUDIO_DIR, \"*.wav\")))\n",
        "print(f\"‚úÖ Total Audio Files Ready: {len(files)}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. GPU PITCH EXTRACTION (OPTIMIZED: ARGMAX + BATCHING)\n",
        "# ==============================================================================\n",
        "print(f\"\\nüéµ Starting CREPE Pitch Extraction on {len(files)} files...\")\n",
        "print(\"   (Using GPU Resampling + Argmax Decoding for Speed)\")\n",
        "\n",
        "# OPTIMIZATION SETTINGS\n",
        "BATCH_SIZE = 2048\n",
        "HOP_LENGTH = 160  # Must match training\n",
        "DECODER = torchcrepe.decode.argmax # 3x Faster than Viterbi\n",
        "\n",
        "for path in tqdm(files):\n",
        "    name = os.path.basename(path).replace(\".wav\", \".npy\")\n",
        "    save_path = os.path.join(PITCH_DIR, name)\n",
        "\n",
        "    if os.path.exists(save_path): continue\n",
        "\n",
        "    try:\n",
        "        # 1. Load Audio (CPU)\n",
        "        audio, sr = torchaudio.load(path)\n",
        "\n",
        "        # 2. Move to GPU IMMEDIATELY (Fast Resampling)\n",
        "        audio = audio.to(device)\n",
        "\n",
        "        # 3. Resample on GPU if needed\n",
        "        if sr != 16000:\n",
        "            audio = torchaudio.functional.resample(audio, sr, 16000)\n",
        "\n",
        "        # 4. Mix to Mono on GPU\n",
        "        if audio.shape[0] > 1:\n",
        "            audio = audio.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # 5. CREPE Predict (GPU)\n",
        "        pitch = torchcrepe.predict(\n",
        "            audio,\n",
        "            sample_rate=16000,\n",
        "            hop_length=HOP_LENGTH,\n",
        "            fmin=50,\n",
        "            fmax=2000,\n",
        "            model='tiny',\n",
        "            decoder=DECODER,       # <--- SPEED OPTIMIZATION\n",
        "            batch_size=BATCH_SIZE,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # 6. Post-Process (CPU)\n",
        "        pitch = pitch.squeeze().cpu().numpy()\n",
        "        pitch = np.log1p(pitch) # Log scale matching training\n",
        "\n",
        "        # 7. Save\n",
        "        np.save(save_path, pitch.astype(np.float32))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error on {name}: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ SUCCESS: All {len(files)} pitch vectors saved to {PITCH_DIR}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. SAVE PROCESSED DATA TO DRIVE (AUTO-ZIP)\n",
        "# ==============================================================================\n",
        "# 1. Config\n",
        "SOURCE_DIR = \"/content/all_pitch\"  # Where your .npy files are right now\n",
        "DRIVE_DEST_DIR = \"/content/drive/MyDrive/FIND_TUNE\" # Check if this path exists or needs creation\n",
        "os.makedirs(DRIVE_DEST_DIR, exist_ok=True)\n",
        "\n",
        "TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
        "ZIP_NAME = f\"processed_pitch_vectors_{TIMESTAMP}.zip\"\n",
        "ZIP_PATH_LOCAL = f\"/content/{ZIP_NAME}\"\n",
        "ZIP_PATH_DRIVE = os.path.join(DRIVE_DEST_DIR, ZIP_NAME)\n",
        "\n",
        "print(f\"\\nüì¶ Zipping {len(os.listdir(SOURCE_DIR))} files from {SOURCE_DIR}...\")\n",
        "\n",
        "# 2. Create Zip (shutil.make_archive adds .zip automatically, so we strip it)\n",
        "shutil.make_archive(ZIP_PATH_LOCAL.replace('.zip', ''), 'zip', SOURCE_DIR)\n",
        "\n",
        "# 3. Copy to Drive\n",
        "print(f\"üöÄ Uploading to Drive: {ZIP_PATH_DRIVE} ...\")\n",
        "shutil.copy(ZIP_PATH_LOCAL, ZIP_PATH_DRIVE)\n",
        "\n",
        "if os.path.exists(ZIP_PATH_DRIVE):\n",
        "    print(f\"‚úÖ SUCCESS! Data saved to: {ZIP_PATH_DRIVE}\")\n",
        "    print(f\"   (File size: {os.path.getsize(ZIP_PATH_DRIVE) / 1024 / 1024:.2f} MB)\")\n",
        "else:\n",
        "    print(f\"‚ùå Error: File did not appear on Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 1. OLD ARCHITECTURE (3-Layer CNN)\n",
        "class OldCNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128, 128), nn.ReLU(), nn.Linear(128, embed_dim)\n",
        "        )\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).squeeze(-1)\n",
        "        return F.normalize(self.fc(x), p=2, dim=1)\n",
        "\n",
        "# 2. DEEP ARCHITECTURE (4-Layer CNN)\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim)\n",
        "        )\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).squeeze(-1)\n",
        "        return F.normalize(self.fc(x), p=2, dim=1)\n",
        "\n",
        "# 3. CRNN ARCHITECTURE (CNN + LSTM)\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim)\n",
        "        )\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = x.permute(0, 2, 1) # (Batch, Seq, Feat)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, _ = self.lstm(x)\n",
        "        out = torch.mean(out, dim=1)\n",
        "        return F.normalize(self.fc(out), p=2, dim=1)"
      ],
      "metadata": {
        "id": "2YSqoxmHZ7Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.signal as sg\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- UTILS ---\n",
        "def smooth_pitch(pitch):\n",
        "    return sg.medfilt(pitch, kernel_size=5).astype(np.float32)\n",
        "\n",
        "def augment_clip(arr, mode='clean'):\n",
        "    arr = arr.copy()\n",
        "\n",
        "    if mode == 'clean':\n",
        "        return arr\n",
        "\n",
        "    elif mode == 'soft':\n",
        "        # Light noise + light vibrato\n",
        "        arr += np.random.normal(0, 0.02, size=len(arr))\n",
        "        return arr\n",
        "\n",
        "    elif mode == 'hard':\n",
        "        # Noise + Key Shift + Time Warp\n",
        "        arr += np.random.normal(0, 0.06, size=len(arr)) # Jitter\n",
        "        semitones = np.random.uniform(-3, 3)\n",
        "        arr[arr > 0] += semitones * 0.057 # Shift\n",
        "        if random.random() < 0.8: # Warp\n",
        "            rate = np.random.uniform(0.85, 1.15)\n",
        "            old_idx = np.arange(len(arr))\n",
        "            new_len = int(len(arr) * rate)\n",
        "            new_idx = np.linspace(0, len(arr)-1, new_len)\n",
        "            arr = np.interp(new_idx, old_idx, arr)\n",
        "            # Force length\n",
        "            if len(arr) < 300: arr = np.pad(arr, (0, 300 - len(arr)), 'constant')\n",
        "            else: arr = arr[:300]\n",
        "        return arr\n",
        "\n",
        "    elif mode == 'ultra':\n",
        "        # \"Limit Testing\": Heavy Noise + Extreme Drift + Dropout\n",
        "        arr += np.random.normal(0, 0.1, size=len(arr)) # Heavy Jitter\n",
        "\n",
        "        # Extreme Tempo Drift (Slow down then speed up)\n",
        "        rate = np.linspace(0.8, 1.2, len(arr))\n",
        "        old_idx = np.arange(len(arr))\n",
        "        # Cumulative sum gives the new index mapping\n",
        "        new_idx = np.cumsum(rate)\n",
        "        new_idx = new_idx / new_idx[-1] * (len(arr)-1)\n",
        "        arr = np.interp(np.arange(len(arr)), new_idx, arr)\n",
        "\n",
        "        # Signal Dropout (Simulate bad mic)\n",
        "        mask_size = random.randint(10, 50)\n",
        "        start = random.randint(0, len(arr)-mask_size)\n",
        "        arr[start:start+mask_size] = 0\n",
        "\n",
        "        return arr\n",
        "\n",
        "    return arr\n",
        "\n",
        "def build_db_for_model(model, pitch_dir, smooth_db=False):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    db_embeds = []\n",
        "    metadata = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for f in tqdm(files, desc=\"Building DB\", leave=False):\n",
        "            arr = np.load(f)\n",
        "            if smooth_db: arr = smooth_pitch(arr)\n",
        "\n",
        "            # Windowing\n",
        "            windows = []\n",
        "            offsets = []\n",
        "            i = 0\n",
        "            while i + 300 <= len(arr):\n",
        "                crop = arr[i:i+300]\n",
        "                if np.mean(crop > 0) > 0.1: # Skip silence\n",
        "                    windows.append(crop)\n",
        "                    offsets.append(i/100.0)\n",
        "                i += 150\n",
        "\n",
        "            if not windows: continue\n",
        "\n",
        "            # Batch Inference\n",
        "            w_tensor = torch.from_numpy(np.stack(windows)).float().unsqueeze(1).to(DEVICE)\n",
        "            embeddings = model.forward_one(w_tensor)\n",
        "\n",
        "            db_embeds.append(embeddings)\n",
        "            song_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "            for t in offsets:\n",
        "                metadata.append((song_name, t))\n",
        "\n",
        "    if not db_embeds: return None, None\n",
        "    return torch.cat(db_embeds), metadata\n",
        "\n",
        "def run_evaluation(model, db_tensor, db_meta, pitch_dir, smooth_query=False):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "\n",
        "    modes = ['Clean', 'Soft', 'Hard', 'Ultra']\n",
        "    results = {m: {'top1':0, 'top5':0, 'top10':0} for m in modes}\n",
        "    total_clips = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Eval Loop: All songs, 3 random clips each\n",
        "    for f in tqdm(files, desc=\"Eval Loop\"):\n",
        "        full_arr = np.load(f)\n",
        "        if len(full_arr) < 500: continue\n",
        "        target_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "\n",
        "        # Take 3 random starting points\n",
        "        starts = np.random.randint(0, len(full_arr)-300, 3)\n",
        "\n",
        "        for s in starts:\n",
        "            base_clip = full_arr[s:s+300]\n",
        "            if smooth_query: base_clip = smooth_pitch(base_clip)\n",
        "\n",
        "            total_clips += 1\n",
        "\n",
        "            for mode in modes:\n",
        "                # Augment\n",
        "                aug_clip = augment_clip(base_clip, mode=mode.lower())\n",
        "\n",
        "                # Embed Query\n",
        "                q_tensor = torch.from_numpy(aug_clip).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "                with torch.no_grad():\n",
        "                    q_emb = model.forward_one(q_tensor)\n",
        "\n",
        "                # Geometric Scoring\n",
        "                dists = torch.cdist(q_emb, db_tensor) # (1, DB_Size)\n",
        "                # Optimization: Only top 50 candidates for voting\n",
        "                vals, inds = torch.topk(dists, k=50, largest=False)\n",
        "\n",
        "                votes = defaultdict(float)\n",
        "                q_time = 0 # Single clip query\n",
        "\n",
        "                for k in range(50):\n",
        "                    idx = inds[0, k].item()\n",
        "                    dist = vals[0, k].item()\n",
        "                    m_name, m_time = db_meta[idx]\n",
        "\n",
        "                    # Alignment check (Assuming user query is start of a segment)\n",
        "                    # For single clip query, we trust distance mostly\n",
        "                    score = 1.0 / (dist + 1e-4)\n",
        "                    votes[m_name] += score\n",
        "\n",
        "                ranked = sorted(votes.items(), key=lambda x: x[1], reverse=True)\n",
        "                top_names = [x[0] for x in ranked]\n",
        "\n",
        "                if not top_names: continue\n",
        "\n",
        "                if top_names[0] == target_name: results[mode]['top1'] += 1\n",
        "                if target_name in top_names[:5]: results[mode]['top5'] += 1\n",
        "                if target_name in top_names[:10]: results[mode]['top10'] += 1\n",
        "\n",
        "    return results, total_clips"
      ],
      "metadata": {
        "id": "7gwN05J3Z7TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. MASTER EVALUATION LOOP\n",
        "# ==============================================================================\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Define the Experiment List based on your renaming\n",
        "# Format: (Filename, Class, Needs_Smoothing)\n",
        "experiments = [\n",
        "    (\"OldCNN_NoSmooth.pth\", OldCNN, False),\n",
        "    (\"OldCNN_Smooth.pth\",   OldCNN, True),\n",
        "    (\"DeepCNN_NoSmooth.pth\", DeepCNN, False),\n",
        "    (\"DeepCNN_Smooth.pth\",   DeepCNN, True),\n",
        "    (\"CRNN_NoSmooth.pth\",    CRNN, False),\n",
        "    (\"CRNN_Smooth.pth\",      CRNN, True),\n",
        "]\n",
        "\n",
        "print(f\"üöÄ STARTING MULTI-MODEL EVALUATION\")\n",
        "print(f\"üìÇ Pitch Dir: {PITCH_DIR}\")\n",
        "print(f\"üéÆ Device: {DEVICE}\")\n",
        "\n",
        "final_report = {}\n",
        "\n",
        "for model_name, ModelClass, smooth_on in experiments:\n",
        "    model_path = os.path.join(MODEL_DIR, model_name)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"\\n‚ö†Ô∏è SKIPPING {model_name} (File not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"üß™ TESTING: {model_name}\")\n",
        "    print(f\"   Architecture: {ModelClass.__name__}\")\n",
        "    print(f\"   Smoothing: {'ON' if smooth_on else 'OFF'}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Load Model\n",
        "    model = ModelClass(embed_dim=128).to(DEVICE)\n",
        "    try:\n",
        "        ckpt = torch.load(model_path, map_location=DEVICE)\n",
        "        # Handle different saving formats\n",
        "        if 'model' in ckpt: model.load_state_dict(ckpt['model'])\n",
        "        else: model.load_state_dict(ckpt)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load {model_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 2. Build DB (Specific to this model's weights)\n",
        "    db_tensor, db_meta = build_db_for_model(model, PITCH_DIR, smooth_db=smooth_on)\n",
        "    if db_tensor is None:\n",
        "        print(\"‚ùå DB Build Failed\")\n",
        "        continue\n",
        "\n",
        "    # 3. Run Eval (Clean, Soft, Hard, Ultra)\n",
        "    res, total = run_evaluation(model, db_tensor, db_meta, PITCH_DIR, smooth_query=smooth_on)\n",
        "\n",
        "    # 4. Print & Store Results\n",
        "    print(f\"\\nüìä RESULTS for {model_name} (Total Trials: {total})\")\n",
        "    for mode in ['Clean', 'Soft', 'Hard', 'Ultra']:\n",
        "        t1 = res[mode]['top1'] / total * 100\n",
        "        t5 = res[mode]['top5'] / total * 100\n",
        "        t10 = res[mode]['top10'] / total * 100\n",
        "        print(f\"   {mode:5} | Top-1: {t1:.1f}% | Top-5: {t5:.1f}% | Top-10: {t10:.1f}%\")\n",
        "\n",
        "    final_report[model_name] = res\n",
        "\n",
        "print(\"\\n‚úÖ GLOBAL EVALUATION COMPLETE.\")"
      ],
      "metadata": {
        "id": "9P1FlP1PZ7UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45a2df4-42b3-4a43-aa55-b7cb0bb3e203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING MULTI-MODEL EVALUATION\n",
            "üìÇ Pitch Dir: /content/all_pitch\n",
            "üéÆ Device: cuda\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: OldCNN_NoSmooth.pth\n",
            "   Architecture: OldCNN\n",
            "   Smoothing: OFF\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [02:56<00:00,  9.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for OldCNN_NoSmooth.pth (Total Trials: 4848)\n",
            "   Clean | Top-1: 8.6% | Top-5: 25.6% | Top-10: 36.2%\n",
            "   Soft  | Top-1: 6.7% | Top-5: 20.7% | Top-10: 31.1%\n",
            "   Hard  | Top-1: 1.9% | Top-5: 5.8% | Top-10: 8.7%\n",
            "   Ultra | Top-1: 0.6% | Top-5: 1.6% | Top-10: 3.0%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: OldCNN_Smooth.pth\n",
            "   Architecture: OldCNN\n",
            "   Smoothing: ON\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [02:55<00:00,  9.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for OldCNN_Smooth.pth (Total Trials: 4848)\n",
            "   Clean | Top-1: 9.5% | Top-5: 29.1% | Top-10: 40.7%\n",
            "   Soft  | Top-1: 8.1% | Top-5: 27.3% | Top-10: 39.2%\n",
            "   Hard  | Top-1: 3.8% | Top-5: 15.4% | Top-10: 24.9%\n",
            "   Ultra | Top-1: 0.4% | Top-5: 1.7% | Top-10: 2.7%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: DeepCNN_NoSmooth.pth\n",
            "   Architecture: DeepCNN\n",
            "   Smoothing: OFF\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [02:59<00:00,  8.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for DeepCNN_NoSmooth.pth (Total Trials: 4848)\n",
            "   Clean | Top-1: 13.7% | Top-5: 34.2% | Top-10: 44.9%\n",
            "   Soft  | Top-1: 13.0% | Top-5: 33.7% | Top-10: 44.8%\n",
            "   Hard  | Top-1: 4.5% | Top-5: 17.4% | Top-10: 28.0%\n",
            "   Ultra | Top-1: 0.9% | Top-5: 2.9% | Top-10: 4.4%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: DeepCNN_Smooth.pth\n",
            "   Architecture: DeepCNN\n",
            "   Smoothing: ON\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [03:07<00:00,  8.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for DeepCNN_Smooth.pth (Total Trials: 4848)\n",
            "   Clean | Top-1: 15.3% | Top-5: 33.4% | Top-10: 43.9%\n",
            "   Soft  | Top-1: 14.0% | Top-5: 32.6% | Top-10: 43.0%\n",
            "   Hard  | Top-1: 5.3% | Top-5: 19.7% | Top-10: 30.8%\n",
            "   Ultra | Top-1: 0.9% | Top-5: 2.6% | Top-10: 4.3%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: CRNN_NoSmooth.pth\n",
            "   Architecture: CRNN\n",
            "   Smoothing: OFF\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [04:02<00:00,  6.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for CRNN_NoSmooth.pth (Total Trials: 4848)\n",
            "   Clean | Top-1: 10.9% | Top-5: 29.5% | Top-10: 39.0%\n",
            "   Soft  | Top-1: 9.9% | Top-5: 28.4% | Top-10: 38.4%\n",
            "   Hard  | Top-1: 4.2% | Top-5: 17.1% | Top-10: 27.1%\n",
            "   Ultra | Top-1: 1.1% | Top-5: 4.4% | Top-10: 7.2%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: CRNN_Smooth.pth\n",
            "   Architecture: CRNN\n",
            "   Smoothing: ON\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [03:55<00:00,  6.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for CRNN_Smooth.pth (Total Trials: 4848)\n",
            "   Clean | Top-1: 13.5% | Top-5: 32.9% | Top-10: 42.9%\n",
            "   Soft  | Top-1: 11.8% | Top-5: 32.0% | Top-10: 42.1%\n",
            "   Hard  | Top-1: 6.1% | Top-5: 23.1% | Top-10: 34.7%\n",
            "   Ultra | Top-1: 1.3% | Top-5: 4.6% | Top-10: 7.7%\n",
            "\n",
            "‚úÖ GLOBAL EVALUATION COMPLETE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ STARTING MULTI-MODEL EVALUATION\n",
        "üìÇ Pitch Dir: /content/all_pitch\n",
        "üéÆ Device: cuda\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: OldCNN_NoSmooth.pth\n",
        "   Architecture: OldCNN\n",
        "   Smoothing: OFF\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [02:56<00:00,  9.18it/s]\n",
        "\n",
        "üìä RESULTS for OldCNN_NoSmooth.pth (Total Trials: 4848)\n",
        "   Clean | Top-1: 8.6% | Top-5: 25.6% | Top-10: 36.2%\n",
        "   Soft  | Top-1: 6.7% | Top-5: 20.7% | Top-10: 31.1%\n",
        "   Hard  | Top-1: 1.9% | Top-5: 5.8% | Top-10: 8.7%\n",
        "   Ultra | Top-1: 0.6% | Top-5: 1.6% | Top-10: 3.0%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: OldCNN_Smooth.pth\n",
        "   Architecture: OldCNN\n",
        "   Smoothing: ON\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [02:55<00:00,  9.20it/s]\n",
        "\n",
        "üìä RESULTS for OldCNN_Smooth.pth (Total Trials: 4848)\n",
        "   Clean | Top-1: 9.5% | Top-5: 29.1% | Top-10: 40.7%\n",
        "   Soft  | Top-1: 8.1% | Top-5: 27.3% | Top-10: 39.2%\n",
        "   Hard  | Top-1: 3.8% | Top-5: 15.4% | Top-10: 24.9%\n",
        "   Ultra | Top-1: 0.4% | Top-5: 1.7% | Top-10: 2.7%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: DeepCNN_NoSmooth.pth\n",
        "   Architecture: DeepCNN\n",
        "   Smoothing: OFF\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [02:59<00:00,  8.99it/s]\n",
        "\n",
        "üìä RESULTS for DeepCNN_NoSmooth.pth (Total Trials: 4848)\n",
        "   Clean | Top-1: 13.7% | Top-5: 34.2% | Top-10: 44.9%\n",
        "   Soft  | Top-1: 13.0% | Top-5: 33.7% | Top-10: 44.8%\n",
        "   Hard  | Top-1: 4.5% | Top-5: 17.4% | Top-10: 28.0%\n",
        "   Ultra | Top-1: 0.9% | Top-5: 2.9% | Top-10: 4.4%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: DeepCNN_Smooth.pth\n",
        "   Architecture: DeepCNN\n",
        "   Smoothing: ON\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [03:07<00:00,  8.62it/s]\n",
        "\n",
        "üìä RESULTS for DeepCNN_Smooth.pth (Total Trials: 4848)\n",
        "   Clean | Top-1: 15.3% | Top-5: 33.4% | Top-10: 43.9%\n",
        "   Soft  | Top-1: 14.0% | Top-5: 32.6% | Top-10: 43.0%\n",
        "   Hard  | Top-1: 5.3% | Top-5: 19.7% | Top-10: 30.8%\n",
        "   Ultra | Top-1: 0.9% | Top-5: 2.6% | Top-10: 4.3%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: CRNN_NoSmooth.pth\n",
        "   Architecture: CRNN\n",
        "   Smoothing: OFF\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [04:02<00:00,  6.65it/s]\n",
        "\n",
        "üìä RESULTS for CRNN_NoSmooth.pth (Total Trials: 4848)\n",
        "   Clean | Top-1: 10.9% | Top-5: 29.5% | Top-10: 39.0%\n",
        "   Soft  | Top-1: 9.9% | Top-5: 28.4% | Top-10: 38.4%\n",
        "   Hard  | Top-1: 4.2% | Top-5: 17.1% | Top-10: 27.1%\n",
        "   Ultra | Top-1: 1.1% | Top-5: 4.4% | Top-10: 7.2%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: CRNN_Smooth.pth\n",
        "   Architecture: CRNN\n",
        "   Smoothing: ON\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1616/1616 [03:55<00:00,  6.85it/s]\n",
        "üìä RESULTS for CRNN_Smooth.pth (Total Trials: 4848)\n",
        "   Clean | Top-1: 13.5% | Top-5: 32.9% | Top-10: 42.9%\n",
        "   Soft  | Top-1: 11.8% | Top-5: 32.0% | Top-10: 42.1%\n",
        "   Hard  | Top-1: 6.1% | Top-5: 23.1% | Top-10: 34.7%\n",
        "   Ultra | Top-1: 1.3% | Top-5: 4.6% | Top-10: 7.7%\n",
        "\n",
        "‚úÖ GLOBAL EVALUATION COMPLETE.\n",
        "\n"
      ],
      "metadata": {
        "id": "sGV01wWDeTIT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P7RIr6Fcg0p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*TRAINING THE TOP 2 MODELS ON A BROADER TRAINING SET*"
      ],
      "metadata": {
        "id": "hFotuD_Og0DE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading dataset"
      ],
      "metadata": {
        "id": "6T4eGzQThUkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP & DATA MERGING\n",
        "# ==============================================================================\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import shutil\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Install Deps\n",
        "print(\"üì¶ Installing Dependencies...\")\n",
        "pkgs = [\"torchcrepe\", \"librosa\", \"torchaudio\", \"tqdm\"]\n",
        "for p in pkgs:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
        "\n",
        "import torch\n",
        "import torchcrepe\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIG ---\n",
        "# Previous Data (Originals)\n",
        "SOURCE_PITCH_ORIGINALS = \"/content/all_pitch\"\n",
        "\n",
        "# New Data Sources (Covers & Extras)\n",
        "ZIP_COVERS = \"/content/drive/MyDrive/FINE_TUNE_V3/train_covers_1300.zip\"\n",
        "DIR_SONGS_1 = \"/content/drive/MyDrive/FINE_TUNE_songs\"\n",
        "DIR_SONGS_2 = \"/content/drive/MyDrive/FINE_TUNE_V3_test/original\"\n",
        "\n",
        "# Output Dirs\n",
        "AUDIO_DIR_NEW = \"/content/expanded_audio_temp\" # Temp folder for just the NEW audio\n",
        "PITCH_DIR_FINAL = \"/content/expanded_pitch\"    # Final folder for ALL pitch\n",
        "\n",
        "# --- PREP DIRECTORIES ---\n",
        "print(f\"\\nüßπ Setting up directories...\")\n",
        "if os.path.exists(AUDIO_DIR_NEW): shutil.rmtree(AUDIO_DIR_NEW)\n",
        "if os.path.exists(PITCH_DIR_FINAL): shutil.rmtree(PITCH_DIR_FINAL)\n",
        "os.makedirs(AUDIO_DIR_NEW, exist_ok=True)\n",
        "os.makedirs(PITCH_DIR_FINAL, exist_ok=True)\n",
        "\n",
        "# --- STEP 1: COPY EXISTING ORIGINALS ---\n",
        "# We verify if the previous step ran. If not, we warn you.\n",
        "if os.path.exists(SOURCE_PITCH_ORIGINALS) and len(os.listdir(SOURCE_PITCH_ORIGINALS)) > 100:\n",
        "    print(f\"‚úÖ Found {len(os.listdir(SOURCE_PITCH_ORIGINALS))} processed originals.\")\n",
        "    print(f\"   Copying to {PITCH_DIR_FINAL}...\")\n",
        "    subprocess.run(f\"cp -r '{SOURCE_PITCH_ORIGINALS}/.' '{PITCH_DIR_FINAL}/'\", shell=True)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: '/content/all_pitch' is missing or empty!\")\n",
        "    print(\"   Did you run the previous 'Mega Data Extraction' block?\")\n",
        "    # If you have the zip in Drive, you could add a line here to unzip it.\n",
        "\n",
        "# --- STEP 2: GATHER NEW AUDIO (Covers) ---\n",
        "print(\"\\nüìÇ Gathering NEW Audio (Covers & Extras)...\")\n",
        "\n",
        "# 1. Unzip Covers\n",
        "if os.path.exists(ZIP_COVERS):\n",
        "    subprocess.run(f\"unzip -q -n '{ZIP_COVERS}' -d '{AUDIO_DIR_NEW}'\", shell=True)\n",
        "    print(f\"   Unzipped Covers.\")\n",
        "\n",
        "# 2. Copy Loose Songs\n",
        "if os.path.exists(DIR_SONGS_1):\n",
        "    subprocess.run(f\"cp -r '{DIR_SONGS_1}/.' '{AUDIO_DIR_NEW}/'\", shell=True)\n",
        "if os.path.exists(DIR_SONGS_2):\n",
        "    subprocess.run(f\"cp -r '{DIR_SONGS_2}/.' '{AUDIO_DIR_NEW}/'\", shell=True)\n",
        "\n",
        "# Flatten\n",
        "for root, dirs, files in os.walk(AUDIO_DIR_NEW):\n",
        "    for file in files:\n",
        "        if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n",
        "            shutil.move(os.path.join(root, file), os.path.join(AUDIO_DIR_NEW, file))\n",
        "\n",
        "new_files = sorted(glob.glob(os.path.join(AUDIO_DIR_NEW, \"*\")))\n",
        "print(f\"‚úÖ New Files to Process: {len(new_files)}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. OPTIMIZED PITCH EXTRACTION (NEW FILES ONLY)\n",
        "# ==============================================================================\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device == 'cpu':\n",
        "    raise RuntimeError(\"‚ùå STOP! Enable GPU.\")\n",
        "\n",
        "print(f\"\\nüéµ Extracting Pitch for {len(new_files)} NEW files...\")\n",
        "\n",
        "BATCH_SIZE = 2048\n",
        "for path in tqdm(new_files):\n",
        "    name = os.path.basename(path)\n",
        "    if name.endswith(\".wav\"): name = name.replace(\".wav\", \".npy\")\n",
        "    elif name.endswith(\".mp3\"): name = name.replace(\".mp3\", \".npy\")\n",
        "\n",
        "    save_path = os.path.join(PITCH_DIR_FINAL, name)\n",
        "\n",
        "    # Skip if we already have this pitch (e.g., from the originals copy)\n",
        "    if os.path.exists(save_path): continue\n",
        "\n",
        "    try:\n",
        "        # Load\n",
        "        audio, sr = torchaudio.load(path)\n",
        "        audio = audio.to(device)\n",
        "\n",
        "        # Resample\n",
        "        if sr != 16000:\n",
        "            audio = torchaudio.functional.resample(audio, sr, 16000)\n",
        "        if audio.shape[0] > 1:\n",
        "            audio = audio.mean(dim=0, keepdim=True)\n",
        "\n",
        "        # Predict (Argmax)\n",
        "        pitch = torchcrepe.predict(\n",
        "            audio, sample_rate=16000, hop_length=160,\n",
        "            fmin=50, fmax=2000, model='tiny',\n",
        "            decoder=torchcrepe.decode.argmax,\n",
        "            batch_size=BATCH_SIZE, device=device\n",
        "        )\n",
        "\n",
        "        # Save\n",
        "        pitch = pitch.squeeze().cpu().numpy()\n",
        "        pitch = np.log1p(pitch)\n",
        "        np.save(save_path, pitch.astype(np.float32))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error on {name}: {e}\")\n",
        "\n",
        "total_count = len(os.listdir(PITCH_DIR_FINAL))\n",
        "print(f\"\\n‚úÖ TOTAL EXPANDED DATASET SIZE: {total_count} files.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. SAVE DATASET TO DRIVE\n",
        "# ==============================================================================\n",
        "print(f\"\\nüì¶ Saving Expanded Pitch Dataset to Drive...\")\n",
        "ZIP_NAME = \"processed_pitch_vectors_EXPANDED\"\n",
        "shutil.make_archive(f\"/content/{ZIP_NAME}\", 'zip', PITCH_DIR_FINAL)\n",
        "\n",
        "DEST = f\"/content/drive/MyDrive/FIND_TUNE/{ZIP_NAME}.zip\"\n",
        "shutil.copy(f\"/content/{ZIP_NAME}.zip\", DEST).\n",
        "\n",
        "print(f\"‚úÖ Saved: {DEST}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHTtkYbmeSmB",
        "outputId": "2ab8d38f-a7fe-48d3-86ac-e2d54aaf9602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing Dependencies...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "üßπ Setting up directories...\n",
            "‚úÖ Found 1616 processed originals.\n",
            "   Copying to /content/expanded_pitch...\n",
            "\n",
            "üìÇ Gathering NEW Audio (Covers & Extras)...\n",
            "   Unzipped Covers.\n",
            "‚úÖ New Files to Process: 1527\n",
            "\n",
            "üéµ Extracting Pitch for 1527 NEW files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1527/1527 [24:42<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ TOTAL EXPANDED DATASET SIZE: 2944 files.\n",
            "\n",
            "üì¶ Saving Expanded Pitch Dataset to Drive...\n",
            "‚úÖ Saved: /content/drive/MyDrive/FIND_TUNE/processed_pitch_vectors_EXPANDED.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training on new dataset (finetuning the top 2 previous model on new data)"
      ],
      "metadata": {
        "id": "ck1PQ2SjhX0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 4. FINE-TUNE SETUP (FIXED: REMOVED VERBOSE ARG)\n",
        "# ==============================================================================\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import random\n",
        "import scipy.signal as sg\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# --- CONFIG ---\n",
        "PITCH_DIR = \"/content/expanded_pitch\"\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/testing_models\"\n",
        "SAVE_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# --- DATASET CLASS ---\n",
        "class PitchDataset(Dataset):\n",
        "    def __init__(self, pitch_dir):\n",
        "        self.files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "\n",
        "    def __len__(self): return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Anchor\n",
        "        anchor = np.load(self.files[idx])\n",
        "        # Negative (Random other song)\n",
        "        neg_idx = random.randint(0, len(self.files)-1)\n",
        "        while neg_idx == idx: neg_idx = random.randint(0, len(self.files)-1)\n",
        "        neg = np.load(self.files[neg_idx])\n",
        "\n",
        "        # Smooth\n",
        "        anchor = sg.medfilt(anchor, 5).astype(np.float32)\n",
        "        neg = sg.medfilt(neg, 5).astype(np.float32)\n",
        "\n",
        "        # Crop 300\n",
        "        def get_crop(arr):\n",
        "            if len(arr) < 300: return np.pad(arr, (0, 300-len(arr)), 'constant')\n",
        "            start = random.randint(0, len(arr)-300)\n",
        "            return arr[start:start+300]\n",
        "\n",
        "        a_crop = get_crop(anchor)\n",
        "        n_crop = get_crop(neg)\n",
        "\n",
        "        # Augment Anchor -> Positive\n",
        "        # We make the positive slightly harder here to simulate a cover\n",
        "        p_crop = a_crop.copy()\n",
        "        p_crop += np.random.normal(0, 0.06, 300) # Slightly more noise for robustness\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(a_crop).float().unsqueeze(0),\n",
        "            torch.from_numpy(p_crop).float().unsqueeze(0),\n",
        "            torch.from_numpy(n_crop).float().unsqueeze(0)\n",
        "        )\n",
        "\n",
        "# --- ARCHITECTURES (Must match saved weights) ---\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, 128))\n",
        "    def forward_one(self, x): return F.normalize(self.fc(self.cnn(x).squeeze(-1)), p=2, dim=1)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, 128))\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).permute(0, 2, 1)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, _ = self.lstm(x)\n",
        "        return F.normalize(self.fc(torch.mean(out, dim=1)), p=2, dim=1)\n",
        "\n",
        "# --- TRAIN LOOP ---\n",
        "def finetune_model(model_name, ModelClass, epochs=60):\n",
        "    print(f\"\\nüöÄ Fine-Tuning: {model_name}\")\n",
        "    print(f\"   Configs: Epochs=60 | Start LR=0.0001 | Patience=4\")\n",
        "\n",
        "    # 1. Load Pre-trained\n",
        "    model = ModelClass().to(DEVICE)\n",
        "    path = os.path.join(MODEL_DIR, model_name)\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"‚ùå Skipping {model_name} (Not found)\")\n",
        "        return\n",
        "\n",
        "    ckpt = torch.load(path, map_location=DEVICE)\n",
        "    if 'model' in ckpt: model.load_state_dict(ckpt['model'])\n",
        "    else: model.load_state_dict(ckpt)\n",
        "    print(\"   ‚úÖ Weights Loaded\")\n",
        "\n",
        "    # 2. Setup\n",
        "    dataset = PitchDataset(PITCH_DIR)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # OPTIMIZER STARTING AT 0.0001\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # ADAPTIVE SCHEDULER (FIXED: Removed verbose=True)\n",
        "    scheduler = ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=4)\n",
        "\n",
        "    loss_fn = nn.TripletMarginLoss(margin=0.85, p=2)\n",
        "\n",
        "    # 3. Loop\n",
        "    model.train()\n",
        "    best_loss = float('inf')\n",
        "    save_path = \"\" # Init variable\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        total_loss = 0\n",
        "        for a, p, n in loader:\n",
        "            a, p, n = a.to(DEVICE), p.to(DEVICE), n.to(DEVICE)\n",
        "            optim.zero_grad()\n",
        "            loss = loss_fn(model.forward_one(a), model.forward_one(p), model.forward_one(n))\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        current_lr = optim.param_groups[0]['lr']\n",
        "        print(f\"   Epoch {ep+1}/{epochs} | Loss: {avg_loss:.4f} | LR: {current_lr:.6f}\")\n",
        "\n",
        "        # Step the scheduler based on loss\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        # Save Best Checkpoint\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            save_path = os.path.join(SAVE_DIR, f\"FINETUNED_{model_name}\")\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"‚úÖ Finished. Best Loss: {best_loss:.4f}\")\n",
        "    print(f\"   Saved to: {save_path}\")\n",
        "\n",
        "# --- EXECUTE ---\n",
        "finetune_model(\"DeepCNN_Smooth.pth\", DeepCNN)\n",
        "finetune_model(\"CRNN_Smooth.pth\", CRNN)"
      ],
      "metadata": {
        "id": "HM86fqY_Z7U2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eefb5bbb-a126-4715-84b3-097c284e19db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Fine-Tuning: DeepCNN_Smooth.pth\n",
            "   Configs: Epochs=60 | Start LR=0.0001 | Patience=4\n",
            "   ‚úÖ Weights Loaded\n",
            "   Epoch 1/60 | Loss: 0.0133 | LR: 0.000100\n",
            "   Epoch 2/60 | Loss: 0.0074 | LR: 0.000100\n",
            "   Epoch 3/60 | Loss: 0.0072 | LR: 0.000100\n",
            "   Epoch 4/60 | Loss: 0.0059 | LR: 0.000100\n",
            "   Epoch 5/60 | Loss: 0.0061 | LR: 0.000100\n",
            "   Epoch 6/60 | Loss: 0.0056 | LR: 0.000100\n",
            "   Epoch 7/60 | Loss: 0.0056 | LR: 0.000100\n",
            "   Epoch 8/60 | Loss: 0.0039 | LR: 0.000100\n",
            "   Epoch 9/60 | Loss: 0.0052 | LR: 0.000100\n",
            "   Epoch 10/60 | Loss: 0.0054 | LR: 0.000100\n",
            "   Epoch 11/60 | Loss: 0.0051 | LR: 0.000100\n",
            "   Epoch 12/60 | Loss: 0.0037 | LR: 0.000100\n",
            "   Epoch 13/60 | Loss: 0.0047 | LR: 0.000100\n",
            "   Epoch 14/60 | Loss: 0.0032 | LR: 0.000100\n",
            "   Epoch 15/60 | Loss: 0.0035 | LR: 0.000100\n",
            "   Epoch 16/60 | Loss: 0.0038 | LR: 0.000100\n",
            "   Epoch 17/60 | Loss: 0.0043 | LR: 0.000100\n",
            "   Epoch 18/60 | Loss: 0.0035 | LR: 0.000100\n",
            "   Epoch 19/60 | Loss: 0.0039 | LR: 0.000100\n",
            "   Epoch 20/60 | Loss: 0.0026 | LR: 0.000050\n",
            "   Epoch 21/60 | Loss: 0.0030 | LR: 0.000050\n",
            "   Epoch 22/60 | Loss: 0.0024 | LR: 0.000050\n",
            "   Epoch 23/60 | Loss: 0.0031 | LR: 0.000050\n",
            "   Epoch 24/60 | Loss: 0.0025 | LR: 0.000050\n",
            "   Epoch 25/60 | Loss: 0.0030 | LR: 0.000050\n",
            "   Epoch 26/60 | Loss: 0.0023 | LR: 0.000050\n",
            "   Epoch 27/60 | Loss: 0.0024 | LR: 0.000050\n",
            "   Epoch 28/60 | Loss: 0.0024 | LR: 0.000050\n",
            "   Epoch 29/60 | Loss: 0.0025 | LR: 0.000050\n",
            "   Epoch 30/60 | Loss: 0.0022 | LR: 0.000050\n",
            "   Epoch 31/60 | Loss: 0.0033 | LR: 0.000050\n",
            "   Epoch 32/60 | Loss: 0.0030 | LR: 0.000050\n",
            "   Epoch 33/60 | Loss: 0.0029 | LR: 0.000050\n",
            "   Epoch 34/60 | Loss: 0.0028 | LR: 0.000050\n",
            "   Epoch 35/60 | Loss: 0.0022 | LR: 0.000050\n",
            "   Epoch 36/60 | Loss: 0.0021 | LR: 0.000025\n",
            "   Epoch 37/60 | Loss: 0.0016 | LR: 0.000025\n",
            "   Epoch 38/60 | Loss: 0.0020 | LR: 0.000025\n",
            "   Epoch 39/60 | Loss: 0.0020 | LR: 0.000025\n",
            "   Epoch 40/60 | Loss: 0.0019 | LR: 0.000025\n",
            "   Epoch 41/60 | Loss: 0.0022 | LR: 0.000025\n",
            "   Epoch 42/60 | Loss: 0.0020 | LR: 0.000025\n",
            "   Epoch 43/60 | Loss: 0.0019 | LR: 0.000013\n",
            "   Epoch 44/60 | Loss: 0.0024 | LR: 0.000013\n",
            "   Epoch 45/60 | Loss: 0.0023 | LR: 0.000013\n",
            "   Epoch 46/60 | Loss: 0.0019 | LR: 0.000013\n",
            "   Epoch 47/60 | Loss: 0.0020 | LR: 0.000013\n",
            "   Epoch 48/60 | Loss: 0.0027 | LR: 0.000006\n",
            "   Epoch 49/60 | Loss: 0.0017 | LR: 0.000006\n",
            "   Epoch 50/60 | Loss: 0.0012 | LR: 0.000006\n",
            "   Epoch 51/60 | Loss: 0.0018 | LR: 0.000006\n",
            "   Epoch 52/60 | Loss: 0.0015 | LR: 0.000006\n",
            "   Epoch 53/60 | Loss: 0.0015 | LR: 0.000006\n",
            "   Epoch 54/60 | Loss: 0.0013 | LR: 0.000006\n",
            "   Epoch 55/60 | Loss: 0.0016 | LR: 0.000006\n",
            "   Epoch 56/60 | Loss: 0.0013 | LR: 0.000003\n",
            "   Epoch 57/60 | Loss: 0.0018 | LR: 0.000003\n",
            "   Epoch 58/60 | Loss: 0.0016 | LR: 0.000003\n",
            "   Epoch 59/60 | Loss: 0.0011 | LR: 0.000003\n",
            "   Epoch 60/60 | Loss: 0.0020 | LR: 0.000003\n",
            "‚úÖ Finished. Best Loss: 0.0011\n",
            "   Saved to: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models/FINETUNED_DeepCNN_Smooth.pth\n",
            "\n",
            "üöÄ Fine-Tuning: CRNN_Smooth.pth\n",
            "   Configs: Epochs=60 | Start LR=0.0001 | Patience=4\n",
            "   ‚úÖ Weights Loaded\n",
            "   Epoch 1/60 | Loss: 0.0109 | LR: 0.000100\n",
            "   Epoch 2/60 | Loss: 0.0063 | LR: 0.000100\n",
            "   Epoch 3/60 | Loss: 0.0042 | LR: 0.000100\n",
            "   Epoch 4/60 | Loss: 0.0038 | LR: 0.000100\n",
            "   Epoch 5/60 | Loss: 0.0049 | LR: 0.000100\n",
            "   Epoch 6/60 | Loss: 0.0039 | LR: 0.000100\n",
            "   Epoch 7/60 | Loss: 0.0043 | LR: 0.000100\n",
            "   Epoch 8/60 | Loss: 0.0043 | LR: 0.000100\n",
            "   Epoch 9/60 | Loss: 0.0038 | LR: 0.000100\n",
            "   Epoch 10/60 | Loss: 0.0035 | LR: 0.000100\n",
            "   Epoch 11/60 | Loss: 0.0035 | LR: 0.000100\n",
            "   Epoch 12/60 | Loss: 0.0032 | LR: 0.000100\n",
            "   Epoch 13/60 | Loss: 0.0023 | LR: 0.000100\n",
            "   Epoch 14/60 | Loss: 0.0036 | LR: 0.000100\n",
            "   Epoch 15/60 | Loss: 0.0035 | LR: 0.000100\n",
            "   Epoch 16/60 | Loss: 0.0025 | LR: 0.000100\n",
            "   Epoch 17/60 | Loss: 0.0026 | LR: 0.000100\n",
            "   Epoch 18/60 | Loss: 0.0022 | LR: 0.000100\n",
            "   Epoch 19/60 | Loss: 0.0023 | LR: 0.000100\n",
            "   Epoch 20/60 | Loss: 0.0022 | LR: 0.000100\n",
            "   Epoch 21/60 | Loss: 0.0024 | LR: 0.000100\n",
            "   Epoch 22/60 | Loss: 0.0030 | LR: 0.000100\n",
            "   Epoch 23/60 | Loss: 0.0024 | LR: 0.000100\n",
            "   Epoch 24/60 | Loss: 0.0020 | LR: 0.000100\n",
            "   Epoch 25/60 | Loss: 0.0021 | LR: 0.000100\n",
            "   Epoch 26/60 | Loss: 0.0020 | LR: 0.000100\n",
            "   Epoch 27/60 | Loss: 0.0024 | LR: 0.000100\n",
            "   Epoch 28/60 | Loss: 0.0016 | LR: 0.000100\n",
            "   Epoch 29/60 | Loss: 0.0023 | LR: 0.000100\n",
            "   Epoch 30/60 | Loss: 0.0016 | LR: 0.000100\n",
            "   Epoch 31/60 | Loss: 0.0021 | LR: 0.000100\n",
            "   Epoch 32/60 | Loss: 0.0019 | LR: 0.000100\n",
            "   Epoch 33/60 | Loss: 0.0022 | LR: 0.000100\n",
            "   Epoch 34/60 | Loss: 0.0015 | LR: 0.000050\n",
            "   Epoch 35/60 | Loss: 0.0017 | LR: 0.000050\n",
            "   Epoch 36/60 | Loss: 0.0016 | LR: 0.000050\n",
            "   Epoch 37/60 | Loss: 0.0012 | LR: 0.000050\n",
            "   Epoch 38/60 | Loss: 0.0015 | LR: 0.000050\n",
            "   Epoch 39/60 | Loss: 0.0012 | LR: 0.000050\n",
            "   Epoch 40/60 | Loss: 0.0012 | LR: 0.000050\n",
            "   Epoch 41/60 | Loss: 0.0010 | LR: 0.000050\n",
            "   Epoch 42/60 | Loss: 0.0008 | LR: 0.000050\n",
            "   Epoch 43/60 | Loss: 0.0010 | LR: 0.000050\n",
            "   Epoch 44/60 | Loss: 0.0018 | LR: 0.000050\n",
            "   Epoch 45/60 | Loss: 0.0011 | LR: 0.000050\n",
            "   Epoch 46/60 | Loss: 0.0012 | LR: 0.000050\n",
            "   Epoch 47/60 | Loss: 0.0014 | LR: 0.000050\n",
            "   Epoch 48/60 | Loss: 0.0012 | LR: 0.000025\n",
            "   Epoch 49/60 | Loss: 0.0007 | LR: 0.000025\n",
            "   Epoch 50/60 | Loss: 0.0007 | LR: 0.000025\n",
            "   Epoch 51/60 | Loss: 0.0014 | LR: 0.000025\n",
            "   Epoch 52/60 | Loss: 0.0007 | LR: 0.000025\n",
            "   Epoch 53/60 | Loss: 0.0004 | LR: 0.000025\n",
            "   Epoch 54/60 | Loss: 0.0004 | LR: 0.000025\n",
            "   Epoch 55/60 | Loss: 0.0007 | LR: 0.000025\n",
            "   Epoch 56/60 | Loss: 0.0008 | LR: 0.000025\n",
            "   Epoch 57/60 | Loss: 0.0008 | LR: 0.000025\n",
            "   Epoch 58/60 | Loss: 0.0013 | LR: 0.000025\n",
            "   Epoch 59/60 | Loss: 0.0013 | LR: 0.000025\n",
            "   Epoch 60/60 | Loss: 0.0012 | LR: 0.000013\n",
            "‚úÖ Finished. Best Loss: 0.0004\n",
            "   Saved to: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models/FINETUNED_CRNN_Smooth.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATING THE NOW FINETUNED MODELS"
      ],
      "metadata": {
        "id": "_naCcBJSjH6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 5. EVALUATION OF FINE-TUNED MODELS\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import scipy.signal as sg\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIG ---\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Data: The Giant Expanded Dataset\n",
        "PITCH_DIR = \"/content/expanded_pitch\"\n",
        "\n",
        "# Models: The New Fine-Tuned Weights\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models\"\n",
        "\n",
        "# --- ARCHITECTURES (Must match training exactly) ---\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
        "    def forward_one(self, x): return F.normalize(self.fc(self.cnn(x).squeeze(-1)), p=2, dim=1)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).permute(0, 2, 1)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, _ = self.lstm(x)\n",
        "        return F.normalize(self.fc(torch.mean(out, dim=1)), p=2, dim=1)\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def smooth_pitch(pitch):\n",
        "    return sg.medfilt(pitch, kernel_size=5).astype(np.float32)\n",
        "\n",
        "def augment_clip(arr, mode='clean'):\n",
        "    arr = arr.copy()\n",
        "    if mode == 'clean': return arr\n",
        "\n",
        "    elif mode == 'soft': # Light Noise\n",
        "        return arr + np.random.normal(0, 0.02, size=len(arr))\n",
        "\n",
        "    elif mode == 'hard': # Noise + Key Shift + Time Warp\n",
        "        arr += np.random.normal(0, 0.06, size=len(arr))\n",
        "        arr[arr > 0] += np.random.uniform(-3, 3) * 0.057\n",
        "        if random.random() < 0.8: # Warp\n",
        "            rate = np.random.uniform(0.85, 1.15)\n",
        "            new_idx = np.linspace(0, len(arr)-1, int(len(arr)*rate))\n",
        "            arr = np.interp(new_idx, np.arange(len(arr)), arr)\n",
        "            if len(arr) < 300: arr = np.pad(arr, (0, 300-len(arr)), 'constant')\n",
        "            else: arr = arr[:300]\n",
        "        return arr\n",
        "\n",
        "    elif mode == 'ultra': # The Stress Test\n",
        "        arr += np.random.normal(0, 0.1, size=len(arr))\n",
        "        # Cumulative drift (tempo drift)\n",
        "        rate = np.cumsum(np.linspace(0.8, 1.2, len(arr)))\n",
        "        rate = rate / rate[-1] * (len(arr)-1)\n",
        "        arr = np.interp(np.arange(len(arr)), rate, arr)\n",
        "        return arr\n",
        "    return arr\n",
        "\n",
        "def build_db_for_model(model, pitch_dir):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    db_embeds = []\n",
        "    metadata = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for f in tqdm(files, desc=\"Building DB\", leave=False):\n",
        "            arr = np.load(f)\n",
        "            arr = smooth_pitch(arr) # Always smooth DB tracks\n",
        "\n",
        "            # Windowing (3s windows, 1.5s hop)\n",
        "            windows = []\n",
        "            offsets = []\n",
        "            i = 0\n",
        "            while i + 300 <= len(arr):\n",
        "                crop = arr[i:i+300]\n",
        "                if np.mean(crop > 0) > 0.1: # Skip silence\n",
        "                    windows.append(crop)\n",
        "                    offsets.append(i/100.0)\n",
        "                i += 150\n",
        "\n",
        "            if not windows: continue\n",
        "\n",
        "            # Batch Inference\n",
        "            w_tensor = torch.from_numpy(np.stack(windows)).float().unsqueeze(1).to(DEVICE)\n",
        "            # Batch processing to avoid OOM on huge files\n",
        "            batch_size = 512\n",
        "            for k in range(0, len(w_tensor), batch_size):\n",
        "                batch = w_tensor[k:k+batch_size]\n",
        "                embeddings = model.forward_one(batch)\n",
        "                db_embeds.append(embeddings)\n",
        "\n",
        "            song_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "            for t in offsets:\n",
        "                metadata.append((song_name, t))\n",
        "\n",
        "    if not db_embeds: return None, None\n",
        "    return torch.cat(db_embeds), metadata\n",
        "\n",
        "def run_evaluation(model, db_tensor, db_meta, pitch_dir):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    # Pick random subset of 300 songs for evaluation speed\n",
        "    # (Checking all 1600+ takes too long, 300 is statistically significant)\n",
        "    if len(files) > 300:\n",
        "        random.shuffle(files)\n",
        "        files = files[:300]\n",
        "\n",
        "    modes = ['Clean', 'Soft', 'Hard', 'Ultra']\n",
        "    results = {m: {'top1':0, 'top5':0, 'top10':0} for m in modes}\n",
        "    total_clips = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for f in tqdm(files, desc=\"Eval Loop\"):\n",
        "        full_arr = np.load(f)\n",
        "        if len(full_arr) < 500: continue\n",
        "        target_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "\n",
        "        # Take 3 random starting points per song\n",
        "        starts = np.random.randint(0, len(full_arr)-300, 3)\n",
        "\n",
        "        for s in starts:\n",
        "            base_clip = full_arr[s:s+300]\n",
        "            base_clip = smooth_pitch(base_clip) # Always smooth query\n",
        "\n",
        "            total_clips += 1\n",
        "\n",
        "            for mode in modes:\n",
        "                aug_clip = augment_clip(base_clip, mode=mode.lower())\n",
        "                q_tensor = torch.from_numpy(aug_clip).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    q_emb = model.forward_one(q_tensor)\n",
        "\n",
        "                # Geometric Scoring\n",
        "                dists = torch.cdist(q_emb, db_tensor)\n",
        "                vals, inds = torch.topk(dists, k=50, largest=False)\n",
        "\n",
        "                votes = defaultdict(float)\n",
        "                for k in range(50):\n",
        "                    idx = inds[0, k].item()\n",
        "                    dist = vals[0, k].item()\n",
        "                    m_name, m_time = db_meta[idx]\n",
        "                    score = 1.0 / (dist + 1e-4)\n",
        "                    votes[m_name] += score\n",
        "\n",
        "                ranked = sorted(votes.items(), key=lambda x: x[1], reverse=True)\n",
        "                top_names = [x[0] for x in ranked]\n",
        "\n",
        "                if not top_names: continue\n",
        "\n",
        "                if top_names[0] == target_name: results[mode]['top1'] += 1\n",
        "                if target_name in top_names[:5]: results[mode]['top5'] += 1\n",
        "                if target_name in top_names[:10]: results[mode]['top10'] += 1\n",
        "\n",
        "    return results, total_clips\n",
        "\n",
        "# ==============================================================================\n",
        "# MASTER LOOP (FINE-TUNED MODELS)\n",
        "# ==============================================================================\n",
        "experiments = [\n",
        "    (\"FINETUNED_DeepCNN_Smooth.pth\", DeepCNN),\n",
        "    (\"FINETUNED_CRNN_Smooth.pth\",    CRNN),\n",
        "]\n",
        "\n",
        "print(f\"üöÄ STARTING FINE-TUNED MODEL EVALUATION\")\n",
        "print(f\"üìÇ Pitch Dir: {PITCH_DIR}\")\n",
        "print(f\"üìÇ Model Dir: {MODEL_DIR}\")\n",
        "\n",
        "for model_name, ModelClass in experiments:\n",
        "    model_path = os.path.join(MODEL_DIR, model_name)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"\\n‚ö†Ô∏è SKIPPING {model_name} (File not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"üß™ TESTING: {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Load\n",
        "    model = ModelClass(embed_dim=128).to(DEVICE)\n",
        "    try:\n",
        "        ckpt = torch.load(model_path, map_location=DEVICE)\n",
        "        if 'model' in ckpt: model.load_state_dict(ckpt['model'])\n",
        "        else: model.load_state_dict(ckpt)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 2. Build DB\n",
        "    db_tensor, db_meta = build_db_for_model(model, PITCH_DIR)\n",
        "    if db_tensor is None: continue\n",
        "\n",
        "    # 3. Eval\n",
        "    res, total = run_evaluation(model, db_tensor, db_meta, PITCH_DIR)\n",
        "\n",
        "    # 4. Report\n",
        "    print(f\"\\nüìä RESULTS for {model_name} (Total Trials: {total})\")\n",
        "    for mode in ['Clean', 'Soft', 'Hard', 'Ultra']:\n",
        "        t1 = res[mode]['top1'] / total * 100\n",
        "        t5 = res[mode]['top5'] / total * 100\n",
        "        t10 = res[mode]['top10'] / total * 100\n",
        "        print(f\"   {mode:5} | Top-1: {t1:.1f}% | Top-5: {t5:.1f}% | Top-10: {t10:.1f}%\")\n",
        "\n",
        "print(\"\\n‚úÖ DONE.\")"
      ],
      "metadata": {
        "id": "H_RYaXfQZ7Vp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805bbfc6-1836-4f21-903d-f862c409a06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING FINE-TUNED MODEL EVALUATION\n",
            "üìÇ Pitch Dir: /content/expanded_pitch\n",
            "üìÇ Model Dir: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: FINETUNED_DeepCNN_Smooth.pth\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:47<00:00,  6.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for FINETUNED_DeepCNN_Smooth.pth (Total Trials: 900)\n",
            "   Clean | Top-1: 23.8% | Top-5: 49.4% | Top-10: 62.9%\n",
            "   Soft  | Top-1: 23.1% | Top-5: 49.7% | Top-10: 63.2%\n",
            "   Hard  | Top-1: 5.0% | Top-5: 13.0% | Top-10: 19.1%\n",
            "   Ultra | Top-1: 10.3% | Top-5: 35.0% | Top-10: 50.2%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: FINETUNED_CRNN_Smooth.pth\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:57<00:00,  5.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for FINETUNED_CRNN_Smooth.pth (Total Trials: 900)\n",
            "   Clean | Top-1: 21.7% | Top-5: 48.3% | Top-10: 62.7%\n",
            "   Soft  | Top-1: 21.6% | Top-5: 49.0% | Top-10: 61.8%\n",
            "   Hard  | Top-1: 6.2% | Top-5: 19.7% | Top-10: 27.4%\n",
            "   Ultra | Top-1: 12.2% | Top-5: 39.7% | Top-10: 54.7%\n",
            "\n",
            "‚úÖ DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================\n",
        "üß™ TESTING: FINETUNED_DeepCNN_Smooth.pth\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:48<00:00,  6.20it/s]\n",
        "\n",
        "üìä RESULTS for FINETUNED_DeepCNN_Smooth.pth (Total Trials: 900)\n",
        "   Clean | Top-1: 22.8% | Top-5: 52.3% | Top-10: 62.9%\n",
        "   Soft  | Top-1: 23.2% | Top-5: 52.4% | Top-10: 63.0%\n",
        "   Hard  | Top-1: 4.9% | Top-5: 14.6% | Top-10: 21.1%\n",
        "   Ultra | Top-1: 12.1% | Top-5: 36.4% | Top-10: 52.0%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: FINETUNED_CRNN_Smooth.pth\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:58<00:00,  5.16it/s]\n",
        "üìä RESULTS for FINETUNED_CRNN_Smooth.pth (Total Trials: 900)\n",
        "   Clean | Top-1: 20.0% | Top-5: 49.1% | Top-10: 62.8%\n",
        "   Soft  | Top-1: 18.6% | Top-5: 48.4% | Top-10: 61.8%\n",
        "   Hard  | Top-1: 5.0% | Top-5: 17.6% | Top-10: 26.0%\n",
        "   Ultra | Top-1: 9.6% | Top-5: 37.3% | Top-10: 55.1%\n"
      ],
      "metadata": {
        "id": "9sxn5Q9Awv51"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmRd_v8YyEek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A MORE DYNAMIC FINETUNING HERE WE MAKE POSITIVE PAIR OF THE ANCHOR CLIP ON DIFF AUGMENTATION"
      ],
      "metadata": {
        "id": "p7Iddvs0yDW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# MULTI-TASK FINE-TUNING (TEMPORAL + SOFT + HARD + ULTRA)\n",
        "# ==============================================================================\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import random\n",
        "import scipy.signal as sg\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# --- CONFIG ---\n",
        "PITCH_DIR = \"/content/expanded_pitch\"\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/testing_models\"\n",
        "SAVE_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "TARGET_LEN = 300\n",
        "\n",
        "# --- AUGMENTATION LOGIC ---\n",
        "def get_crop_and_pad(arr, target_len=300):\n",
        "    if len(arr) < target_len:\n",
        "        return np.pad(arr, (0, target_len - len(arr)), 'constant')\n",
        "    start = random.randint(0, len(arr) - target_len)\n",
        "    return arr[start:start + target_len]\n",
        "\n",
        "def augment_pitch(arr, mode):\n",
        "    arr = arr.copy()\n",
        "\n",
        "    if mode == 'soft': # Light Noise\n",
        "        arr += np.random.normal(0, 0.02, size=len(arr))\n",
        "\n",
        "    elif mode == 'hard': # Jitter + Key Shift\n",
        "        arr += np.random.normal(0, 0.06, size=len(arr))\n",
        "        shift = np.random.uniform(-3, 3) * 0.057\n",
        "        arr[arr > 0] += shift\n",
        "\n",
        "    elif mode == 'ultra': # Time Warp + Dropout + Heavy Noise\n",
        "        # 1. Heavy Jitter\n",
        "        arr += np.random.normal(0, 0.1, size=len(arr))\n",
        "\n",
        "        # 2. Time Warp (Tempo Drift)\n",
        "        # We stretch/squash and then re-sample back to target length\n",
        "        rate = np.random.uniform(0.8, 1.2)\n",
        "        old_indices = np.arange(len(arr))\n",
        "        new_length = int(len(arr) * rate)\n",
        "        new_indices = np.linspace(0, len(arr)-1, new_length)\n",
        "        arr = np.interp(new_indices, old_indices, arr)\n",
        "\n",
        "        # 3. Re-Crop/Pad to 300 after warping\n",
        "        if len(arr) != TARGET_LEN:\n",
        "            if len(arr) < TARGET_LEN:\n",
        "                arr = np.pad(arr, (0, TARGET_LEN - len(arr)), 'constant')\n",
        "            else:\n",
        "                start = random.randint(0, len(arr) - TARGET_LEN)\n",
        "                arr = arr[start:start+TARGET_LEN]\n",
        "\n",
        "        # 4. Dropout (Simulate bad mic connection)\n",
        "        if random.random() < 0.5:\n",
        "            drop_len = random.randint(10, 50)\n",
        "            drop_start = random.randint(0, len(arr) - drop_len)\n",
        "            arr[drop_start:drop_start+drop_len] = 0\n",
        "\n",
        "    return arr.astype(np.float32)\n",
        "\n",
        "# --- MULTI-TASK DATASET ---\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, pitch_dir):\n",
        "        self.files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "\n",
        "    def __len__(self): return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Load Anchor File\n",
        "        anchor_full = np.load(self.files[idx])\n",
        "\n",
        "        # 2. Load Negative File\n",
        "        neg_idx = random.randint(0, len(self.files)-1)\n",
        "        while neg_idx == idx:\n",
        "            neg_idx = random.randint(0, len(self.files)-1)\n",
        "        neg_full = np.load(self.files[neg_idx])\n",
        "\n",
        "        # 3. Base Crops (Smoothed)\n",
        "        # Crop A1: The Anchor\n",
        "        a_raw = get_crop_and_pad(anchor_full)\n",
        "        # Crop A2: Different part of same song (For Temporal Task)\n",
        "        p_temporal_raw = get_crop_and_pad(anchor_full)\n",
        "        # Crop N: Negative\n",
        "        n_raw = get_crop_and_pad(neg_full)\n",
        "\n",
        "        # Apply Smoothing\n",
        "        anchor = sg.medfilt(a_raw, 5).astype(np.float32)\n",
        "        pos_temporal = sg.medfilt(p_temporal_raw, 5).astype(np.float32)\n",
        "        neg = sg.medfilt(n_raw, 5).astype(np.float32)\n",
        "\n",
        "        # 4. Generate Augmented Positives (From the Anchor crop)\n",
        "        pos_soft  = augment_pitch(anchor, 'soft')\n",
        "        pos_hard  = augment_pitch(anchor, 'hard')\n",
        "        pos_ultra = augment_pitch(anchor, 'ultra')\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(anchor).float().unsqueeze(0),       # Anchor\n",
        "            torch.from_numpy(pos_temporal).float().unsqueeze(0), # Task 1\n",
        "            torch.from_numpy(pos_soft).float().unsqueeze(0),     # Task 2\n",
        "            torch.from_numpy(pos_hard).float().unsqueeze(0),     # Task 3\n",
        "            torch.from_numpy(pos_ultra).float().unsqueeze(0),    # Task 4\n",
        "            torch.from_numpy(neg).float().unsqueeze(0)           # Negative\n",
        "        )\n",
        "\n",
        "# --- ARCHITECTURES ---\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, 128))\n",
        "    def forward_one(self, x): return F.normalize(self.fc(self.cnn(x).squeeze(-1)), p=2, dim=1)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, 128))\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).permute(0, 2, 1)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, _ = self.lstm(x)\n",
        "        return F.normalize(self.fc(torch.mean(out, dim=1)), p=2, dim=1)\n",
        "\n",
        "# --- MULTI-TASK TRAINING LOOP ---\n",
        "def train_multitask(model_name, ModelClass, epochs=60):\n",
        "    print(f\"\\nüöÄ Multi-Task Training: {model_name}\")\n",
        "    print(f\"   Tasks: Temporal + Soft + Hard + Ultra\")\n",
        "\n",
        "    # 1. Load Base Model\n",
        "    model = ModelClass().to(DEVICE)\n",
        "    path = os.path.join(MODEL_DIR, model_name)\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"‚ùå Skipping {model_name} (Not found)\")\n",
        "        return\n",
        "\n",
        "    ckpt = torch.load(path, map_location=DEVICE)\n",
        "    if 'model' in ckpt: model.load_state_dict(ckpt['model'])\n",
        "    else: model.load_state_dict(ckpt)\n",
        "    print(\"   ‚úÖ Base Weights Loaded\")\n",
        "\n",
        "    # 2. Setup\n",
        "    dataset = MultiTaskDataset(PITCH_DIR)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
        "\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=4)\n",
        "\n",
        "    # Using slightly stricter margin for Hard/Ultra to force separation\n",
        "    loss_fn = nn.TripletMarginLoss(margin=0.85, p=2)\n",
        "\n",
        "    # 3. Loop\n",
        "    model.train()\n",
        "    best_loss = float('inf')\n",
        "    save_path = \"\"\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in loader:\n",
        "            # Unpack all 6 tensors\n",
        "            # anchor, p_temp, p_soft, p_hard, p_ultra, neg\n",
        "            anch, p1, p2, p3, p4, neg = [t.to(DEVICE) for t in batch]\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "            # Forward Pass (Shared Anchor, Shared Negative)\n",
        "            a_emb = model.forward_one(anch)\n",
        "            n_emb = model.forward_one(neg)\n",
        "\n",
        "            # 4x Positive Forward Passes\n",
        "            p1_emb = model.forward_one(p1) # Temporal\n",
        "            p2_emb = model.forward_one(p2) # Soft\n",
        "            p3_emb = model.forward_one(p3) # Hard\n",
        "            p4_emb = model.forward_one(p4) # Ultra\n",
        "\n",
        "            # Calculate 4 Losses\n",
        "            loss1 = loss_fn(a_emb, p1_emb, n_emb)\n",
        "            loss2 = loss_fn(a_emb, p2_emb, n_emb)\n",
        "            loss3 = loss_fn(a_emb, p3_emb, n_emb)\n",
        "            loss4 = loss_fn(a_emb, p4_emb, n_emb)\n",
        "\n",
        "            # Weighted Sum (You can tune weights if needed, equal is usually fine)\n",
        "            combined_loss = loss1 + loss2 + loss3 + loss4\n",
        "\n",
        "            combined_loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            # We track the average individual loss, so divide by 4\n",
        "            total_loss += (combined_loss.item() / 4.0)\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "        current_lr = optim.param_groups[0]['lr']\n",
        "        print(f\"   Epoch {ep+1}/{epochs} | Avg Loss: {avg_loss:.4f} | LR: {current_lr:.6f}\")\n",
        "\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            save_path = os.path.join(SAVE_DIR, f\"MULTITASK_{model_name}\")\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    print(f\"‚úÖ Finished. Best Loss: {best_loss:.4f}\")\n",
        "    print(f\"   Saved to: {save_path}\")\n",
        "\n",
        "# --- EXECUTE ---\n",
        "train_multitask(\"DeepCNN_Smooth.pth\", DeepCNN)\n",
        "train_multitask(\"CRNN_Smooth.pth\", CRNN)"
      ],
      "metadata": {
        "id": "cTpYzwrhZ7Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d1a27e-13a1-46c8-bb30-bd1a4f3434f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Multi-Task Training: DeepCNN_Smooth.pth\n",
            "   Tasks: Temporal + Soft + Hard + Ultra\n",
            "   ‚úÖ Base Weights Loaded\n",
            "   Epoch 1/60 | Avg Loss: 0.2117 | LR: 0.000100\n",
            "   Epoch 2/60 | Avg Loss: 0.1916 | LR: 0.000100\n",
            "   Epoch 3/60 | Avg Loss: 0.1851 | LR: 0.000100\n",
            "   Epoch 4/60 | Avg Loss: 0.1843 | LR: 0.000100\n",
            "   Epoch 5/60 | Avg Loss: 0.1828 | LR: 0.000100\n",
            "   Epoch 6/60 | Avg Loss: 0.1838 | LR: 0.000100\n",
            "   Epoch 7/60 | Avg Loss: 0.1839 | LR: 0.000100\n",
            "   Epoch 8/60 | Avg Loss: 0.1814 | LR: 0.000100\n",
            "   Epoch 9/60 | Avg Loss: 0.1804 | LR: 0.000100\n",
            "   Epoch 10/60 | Avg Loss: 0.1782 | LR: 0.000100\n",
            "   Epoch 11/60 | Avg Loss: 0.1782 | LR: 0.000100\n",
            "   Epoch 12/60 | Avg Loss: 0.1821 | LR: 0.000100\n",
            "   Epoch 13/60 | Avg Loss: 0.1822 | LR: 0.000100\n",
            "   Epoch 14/60 | Avg Loss: 0.1805 | LR: 0.000100\n",
            "   Epoch 15/60 | Avg Loss: 0.1804 | LR: 0.000100\n",
            "   Epoch 16/60 | Avg Loss: 0.1736 | LR: 0.000050\n",
            "   Epoch 17/60 | Avg Loss: 0.1758 | LR: 0.000050\n",
            "   Epoch 18/60 | Avg Loss: 0.1825 | LR: 0.000050\n",
            "   Epoch 19/60 | Avg Loss: 0.1713 | LR: 0.000050\n",
            "   Epoch 20/60 | Avg Loss: 0.1834 | LR: 0.000050\n",
            "   Epoch 21/60 | Avg Loss: 0.1767 | LR: 0.000050\n",
            "   Epoch 22/60 | Avg Loss: 0.1785 | LR: 0.000050\n",
            "   Epoch 23/60 | Avg Loss: 0.1814 | LR: 0.000050\n",
            "   Epoch 24/60 | Avg Loss: 0.1774 | LR: 0.000050\n",
            "   Epoch 25/60 | Avg Loss: 0.1773 | LR: 0.000025\n",
            "   Epoch 26/60 | Avg Loss: 0.1728 | LR: 0.000025\n",
            "   Epoch 27/60 | Avg Loss: 0.1713 | LR: 0.000025\n",
            "   Epoch 28/60 | Avg Loss: 0.1718 | LR: 0.000025\n",
            "   Epoch 29/60 | Avg Loss: 0.1742 | LR: 0.000025\n",
            "   Epoch 30/60 | Avg Loss: 0.1786 | LR: 0.000025\n",
            "   Epoch 31/60 | Avg Loss: 0.1743 | LR: 0.000025\n",
            "   Epoch 32/60 | Avg Loss: 0.1700 | LR: 0.000025\n",
            "   Epoch 33/60 | Avg Loss: 0.1756 | LR: 0.000025\n",
            "   Epoch 34/60 | Avg Loss: 0.1748 | LR: 0.000025\n",
            "   Epoch 35/60 | Avg Loss: 0.1769 | LR: 0.000025\n",
            "   Epoch 36/60 | Avg Loss: 0.1731 | LR: 0.000025\n",
            "   Epoch 37/60 | Avg Loss: 0.1706 | LR: 0.000025\n",
            "   Epoch 38/60 | Avg Loss: 0.1702 | LR: 0.000013\n",
            "   Epoch 39/60 | Avg Loss: 0.1740 | LR: 0.000013\n",
            "   Epoch 40/60 | Avg Loss: 0.1705 | LR: 0.000013\n",
            "   Epoch 41/60 | Avg Loss: 0.1737 | LR: 0.000013\n",
            "   Epoch 42/60 | Avg Loss: 0.1758 | LR: 0.000013\n",
            "   Epoch 43/60 | Avg Loss: 0.1707 | LR: 0.000006\n",
            "   Epoch 44/60 | Avg Loss: 0.1738 | LR: 0.000006\n",
            "   Epoch 45/60 | Avg Loss: 0.1744 | LR: 0.000006\n",
            "   Epoch 46/60 | Avg Loss: 0.1694 | LR: 0.000006\n",
            "   Epoch 47/60 | Avg Loss: 0.1728 | LR: 0.000006\n",
            "   Epoch 48/60 | Avg Loss: 0.1720 | LR: 0.000006\n",
            "   Epoch 49/60 | Avg Loss: 0.1658 | LR: 0.000006\n",
            "   Epoch 50/60 | Avg Loss: 0.1689 | LR: 0.000006\n",
            "   Epoch 51/60 | Avg Loss: 0.1738 | LR: 0.000006\n",
            "   Epoch 52/60 | Avg Loss: 0.1736 | LR: 0.000006\n",
            "   Epoch 53/60 | Avg Loss: 0.1707 | LR: 0.000006\n",
            "   Epoch 54/60 | Avg Loss: 0.1725 | LR: 0.000006\n",
            "   Epoch 55/60 | Avg Loss: 0.1678 | LR: 0.000003\n",
            "   Epoch 56/60 | Avg Loss: 0.1736 | LR: 0.000003\n",
            "   Epoch 57/60 | Avg Loss: 0.1707 | LR: 0.000003\n",
            "   Epoch 58/60 | Avg Loss: 0.1664 | LR: 0.000003\n",
            "   Epoch 59/60 | Avg Loss: 0.1733 | LR: 0.000003\n",
            "   Epoch 60/60 | Avg Loss: 0.1707 | LR: 0.000002\n",
            "‚úÖ Finished. Best Loss: 0.1658\n",
            "   Saved to: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models/MULTITASK_DeepCNN_Smooth.pth\n",
            "\n",
            "üöÄ Multi-Task Training: CRNN_Smooth.pth\n",
            "   Tasks: Temporal + Soft + Hard + Ultra\n",
            "   ‚úÖ Base Weights Loaded\n",
            "   Epoch 1/60 | Avg Loss: 0.2185 | LR: 0.000100\n",
            "   Epoch 2/60 | Avg Loss: 0.1975 | LR: 0.000100\n",
            "   Epoch 3/60 | Avg Loss: 0.1923 | LR: 0.000100\n",
            "   Epoch 4/60 | Avg Loss: 0.1936 | LR: 0.000100\n",
            "   Epoch 5/60 | Avg Loss: 0.1888 | LR: 0.000100\n",
            "   Epoch 6/60 | Avg Loss: 0.1892 | LR: 0.000100\n",
            "   Epoch 7/60 | Avg Loss: 0.1871 | LR: 0.000100\n",
            "   Epoch 8/60 | Avg Loss: 0.1841 | LR: 0.000100\n",
            "   Epoch 9/60 | Avg Loss: 0.1835 | LR: 0.000100\n",
            "   Epoch 10/60 | Avg Loss: 0.1901 | LR: 0.000100\n",
            "   Epoch 11/60 | Avg Loss: 0.1845 | LR: 0.000100\n",
            "   Epoch 12/60 | Avg Loss: 0.1839 | LR: 0.000100\n",
            "   Epoch 13/60 | Avg Loss: 0.1759 | LR: 0.000100\n",
            "   Epoch 14/60 | Avg Loss: 0.1792 | LR: 0.000100\n",
            "   Epoch 15/60 | Avg Loss: 0.1792 | LR: 0.000100\n",
            "   Epoch 16/60 | Avg Loss: 0.1780 | LR: 0.000100\n",
            "   Epoch 17/60 | Avg Loss: 0.1767 | LR: 0.000100\n",
            "   Epoch 18/60 | Avg Loss: 0.1730 | LR: 0.000100\n",
            "   Epoch 19/60 | Avg Loss: 0.1783 | LR: 0.000100\n",
            "   Epoch 20/60 | Avg Loss: 0.1787 | LR: 0.000100\n",
            "   Epoch 21/60 | Avg Loss: 0.1804 | LR: 0.000100\n",
            "   Epoch 22/60 | Avg Loss: 0.1777 | LR: 0.000100\n",
            "   Epoch 23/60 | Avg Loss: 0.1778 | LR: 0.000100\n",
            "   Epoch 24/60 | Avg Loss: 0.1756 | LR: 0.000050\n",
            "   Epoch 25/60 | Avg Loss: 0.1743 | LR: 0.000050\n",
            "   Epoch 26/60 | Avg Loss: 0.1721 | LR: 0.000050\n",
            "   Epoch 27/60 | Avg Loss: 0.1730 | LR: 0.000050\n",
            "   Epoch 28/60 | Avg Loss: 0.1739 | LR: 0.000050\n",
            "   Epoch 29/60 | Avg Loss: 0.1741 | LR: 0.000050\n",
            "   Epoch 30/60 | Avg Loss: 0.1779 | LR: 0.000050\n",
            "   Epoch 31/60 | Avg Loss: 0.1750 | LR: 0.000050\n",
            "   Epoch 32/60 | Avg Loss: 0.1728 | LR: 0.000025\n",
            "   Epoch 33/60 | Avg Loss: 0.1755 | LR: 0.000025\n",
            "   Epoch 34/60 | Avg Loss: 0.1721 | LR: 0.000025\n",
            "   Epoch 35/60 | Avg Loss: 0.1729 | LR: 0.000025\n",
            "   Epoch 36/60 | Avg Loss: 0.1715 | LR: 0.000025\n",
            "   Epoch 37/60 | Avg Loss: 0.1729 | LR: 0.000025\n",
            "   Epoch 38/60 | Avg Loss: 0.1724 | LR: 0.000025\n",
            "   Epoch 39/60 | Avg Loss: 0.1770 | LR: 0.000025\n",
            "   Epoch 40/60 | Avg Loss: 0.1739 | LR: 0.000025\n",
            "   Epoch 41/60 | Avg Loss: 0.1760 | LR: 0.000025\n",
            "   Epoch 42/60 | Avg Loss: 0.1722 | LR: 0.000013\n",
            "   Epoch 43/60 | Avg Loss: 0.1683 | LR: 0.000013\n",
            "   Epoch 44/60 | Avg Loss: 0.1752 | LR: 0.000013\n",
            "   Epoch 45/60 | Avg Loss: 0.1678 | LR: 0.000013\n",
            "   Epoch 46/60 | Avg Loss: 0.1724 | LR: 0.000013\n",
            "   Epoch 47/60 | Avg Loss: 0.1758 | LR: 0.000013\n",
            "   Epoch 48/60 | Avg Loss: 0.1728 | LR: 0.000013\n",
            "   Epoch 49/60 | Avg Loss: 0.1729 | LR: 0.000013\n",
            "   Epoch 50/60 | Avg Loss: 0.1753 | LR: 0.000013\n",
            "   Epoch 51/60 | Avg Loss: 0.1700 | LR: 0.000006\n",
            "   Epoch 52/60 | Avg Loss: 0.1701 | LR: 0.000006\n",
            "   Epoch 53/60 | Avg Loss: 0.1723 | LR: 0.000006\n",
            "   Epoch 54/60 | Avg Loss: 0.1699 | LR: 0.000006\n",
            "   Epoch 55/60 | Avg Loss: 0.1682 | LR: 0.000006\n",
            "   Epoch 56/60 | Avg Loss: 0.1730 | LR: 0.000003\n",
            "   Epoch 57/60 | Avg Loss: 0.1745 | LR: 0.000003\n",
            "   Epoch 58/60 | Avg Loss: 0.1726 | LR: 0.000003\n",
            "   Epoch 59/60 | Avg Loss: 0.1741 | LR: 0.000003\n",
            "   Epoch 60/60 | Avg Loss: 0.1739 | LR: 0.000003\n",
            "‚úÖ Finished. Best Loss: 0.1678\n",
            "   Saved to: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models/MULTITASK_CRNN_Smooth.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVAL"
      ],
      "metadata": {
        "id": "wOdHRtKCyiK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. EVALUATION OF MULTI-TASK MODELS\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import scipy.signal as sg\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIG ---\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Data: The Giant Expanded Dataset\n",
        "PITCH_DIR = \"/content/expanded_pitch\"\n",
        "\n",
        "# Models: Point to where you saved the MULTITASK models\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models\"\n",
        "\n",
        "# --- ARCHITECTURES (Must match training exactly) ---\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
        "    def forward_one(self, x): return F.normalize(self.fc(self.cnn(x).squeeze(-1)), p=2, dim=1)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).permute(0, 2, 1)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, _ = self.lstm(x)\n",
        "        return F.normalize(self.fc(torch.mean(out, dim=1)), p=2, dim=1)\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def smooth_pitch(pitch):\n",
        "    return sg.medfilt(pitch, kernel_size=5).astype(np.float32)\n",
        "\n",
        "def augment_clip(arr, mode='clean'):\n",
        "    arr = arr.copy()\n",
        "    if mode == 'clean': return arr\n",
        "\n",
        "    elif mode == 'soft': # Light Noise\n",
        "        return arr + np.random.normal(0, 0.02, size=len(arr))\n",
        "\n",
        "    elif mode == 'hard': # Noise + Key Shift + Time Warp\n",
        "        arr += np.random.normal(0, 0.06, size=len(arr))\n",
        "        arr[arr > 0] += np.random.uniform(-3, 3) * 0.057\n",
        "        if random.random() < 0.8: # Warp\n",
        "            rate = np.random.uniform(0.85, 1.15)\n",
        "            new_idx = np.linspace(0, len(arr)-1, int(len(arr)*rate))\n",
        "            arr = np.interp(new_idx, np.arange(len(arr)), arr)\n",
        "            if len(arr) < 300: arr = np.pad(arr, (0, 300-len(arr)), 'constant')\n",
        "            else: arr = arr[:300]\n",
        "        return arr\n",
        "\n",
        "    elif mode == 'ultra': # The Stress Test\n",
        "        arr += np.random.normal(0, 0.1, size=len(arr))\n",
        "        # Cumulative drift (tempo drift)\n",
        "        rate = np.cumsum(np.linspace(0.8, 1.2, len(arr)))\n",
        "        rate = rate / rate[-1] * (len(arr)-1)\n",
        "        arr = np.interp(np.arange(len(arr)), rate, arr)\n",
        "        return arr\n",
        "    return arr\n",
        "\n",
        "def build_db_for_model(model, pitch_dir):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    db_embeds = []\n",
        "    metadata = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for f in tqdm(files, desc=\"Building DB\", leave=False):\n",
        "            arr = np.load(f)\n",
        "            arr = smooth_pitch(arr) # Always smooth DB tracks\n",
        "\n",
        "            # Windowing (3s windows, 1.5s hop)\n",
        "            windows = []\n",
        "            offsets = []\n",
        "            i = 0\n",
        "            while i + 300 <= len(arr):\n",
        "                crop = arr[i:i+300]\n",
        "                if np.mean(crop > 0) > 0.1: # Skip silence\n",
        "                    windows.append(crop)\n",
        "                    offsets.append(i/100.0)\n",
        "                i += 150\n",
        "\n",
        "            if not windows: continue\n",
        "\n",
        "            # Batch Inference\n",
        "            w_tensor = torch.from_numpy(np.stack(windows)).float().unsqueeze(1).to(DEVICE)\n",
        "            # Batch processing to avoid OOM on huge files\n",
        "            batch_size = 512\n",
        "            for k in range(0, len(w_tensor), batch_size):\n",
        "                batch = w_tensor[k:k+batch_size]\n",
        "                embeddings = model.forward_one(batch)\n",
        "                db_embeds.append(embeddings)\n",
        "\n",
        "            song_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "            for t in offsets:\n",
        "                metadata.append((song_name, t))\n",
        "\n",
        "    if not db_embeds: return None, None\n",
        "    return torch.cat(db_embeds), metadata\n",
        "\n",
        "def run_evaluation(model, db_tensor, db_meta, pitch_dir):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    # Pick random subset of 300 songs for evaluation speed\n",
        "    # (Checking all 1600+ takes too long, 300 is statistically significant)\n",
        "    if len(files) > 300:\n",
        "        random.shuffle(files)\n",
        "        files = files[:300]\n",
        "\n",
        "    modes = ['Clean', 'Soft', 'Hard', 'Ultra']\n",
        "    results = {m: {'top1':0, 'top5':0, 'top10':0} for m in modes}\n",
        "    total_clips = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for f in tqdm(files, desc=\"Eval Loop\"):\n",
        "        full_arr = np.load(f)\n",
        "        if len(full_arr) < 500: continue\n",
        "        target_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "\n",
        "        # Take 3 random starting points per song\n",
        "        starts = np.random.randint(0, len(full_arr)-300, 3)\n",
        "\n",
        "        for s in starts:\n",
        "            base_clip = full_arr[s:s+300]\n",
        "            base_clip = smooth_pitch(base_clip) # Always smooth query\n",
        "\n",
        "            total_clips += 1\n",
        "\n",
        "            for mode in modes:\n",
        "                aug_clip = augment_clip(base_clip, mode=mode.lower())\n",
        "                q_tensor = torch.from_numpy(aug_clip).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    q_emb = model.forward_one(q_tensor)\n",
        "\n",
        "                # Geometric Scoring\n",
        "                dists = torch.cdist(q_emb, db_tensor)\n",
        "                vals, inds = torch.topk(dists, k=50, largest=False)\n",
        "\n",
        "                votes = defaultdict(float)\n",
        "                for k in range(50):\n",
        "                    idx = inds[0, k].item()\n",
        "                    dist = vals[0, k].item()\n",
        "                    m_name, m_time = db_meta[idx]\n",
        "                    score = 1.0 / (dist + 1e-4)\n",
        "                    votes[m_name] += score\n",
        "\n",
        "                ranked = sorted(votes.items(), key=lambda x: x[1], reverse=True)\n",
        "                top_names = [x[0] for x in ranked]\n",
        "\n",
        "                if not top_names: continue\n",
        "\n",
        "                if top_names[0] == target_name: results[mode]['top1'] += 1\n",
        "                if target_name in top_names[:5]: results[mode]['top5'] += 1\n",
        "                if target_name in top_names[:10]: results[mode]['top10'] += 1\n",
        "\n",
        "    return results, total_clips\n",
        "\n",
        "# ==============================================================================\n",
        "# MASTER LOOP (MULTI-TASK MODELS)\n",
        "# ==============================================================================\n",
        "# Note: I added the '_v2' suffix based on our previous step.\n",
        "# If you didn't use the suffix, just remove it from the string here.\n",
        "experiments = [\n",
        "    (\"MULTITASK_DeepCNN_Smooth.pth\", DeepCNN),\n",
        "    (\"MULTITASK_CRNN_Smooth .pth\",    CRNN),\n",
        "]\n",
        "\n",
        "print(f\"üöÄ STARTING MULTI-TASK MODEL EVALUATION\")\n",
        "print(f\"üìÇ Pitch Dir: {PITCH_DIR}\")\n",
        "print(f\"üìÇ Model Dir: {MODEL_DIR}\")\n",
        "\n",
        "for model_name, ModelClass in experiments:\n",
        "    model_path = os.path.join(MODEL_DIR, model_name)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"\\n‚ö†Ô∏è SKIPPING {model_name} (File not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"üß™ TESTING: {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Load\n",
        "    model = ModelClass(embed_dim=128).to(DEVICE)\n",
        "    try:\n",
        "        ckpt = torch.load(model_path, map_location=DEVICE)\n",
        "        if 'model' in ckpt: model.load_state_dict(ckpt['model'])\n",
        "        else: model.load_state_dict(ckpt)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 2. Build DB\n",
        "    db_tensor, db_meta = build_db_for_model(model, PITCH_DIR)\n",
        "    if db_tensor is None: continue\n",
        "\n",
        "    # 3. Eval\n",
        "    res, total = run_evaluation(model, db_tensor, db_meta, PITCH_DIR)\n",
        "\n",
        "    # 4. Report\n",
        "    print(f\"\\nüìä RESULTS for {model_name} (Total Trials: {total})\")\n",
        "    for mode in ['Clean', 'Soft', 'Hard', 'Ultra']:\n",
        "        t1 = res[mode]['top1'] / total * 100\n",
        "        t5 = res[mode]['top5'] / total * 100\n",
        "        t10 = res[mode]['top10'] / total * 100\n",
        "        print(f\"   {mode:5} | Top-1: {t1:.1f}% | Top-5: {t5:.1f}% | Top-10: {t10:.1f}%\")\n",
        "\n",
        "print(\"\\n‚úÖ DONE.\")"
      ],
      "metadata": {
        "id": "ju9BkCFAZ7Xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54d48e6-f42d-41a1-9142-be67a91f3b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING MULTI-TASK MODEL EVALUATION\n",
            "üìÇ Pitch Dir: /content/expanded_pitch\n",
            "üìÇ Model Dir: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/finetuned_models\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: MULTITASK_DeepCNN_Smooth.pth\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:47<00:00,  6.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for MULTITASK_DeepCNN_Smooth.pth (Total Trials: 900)\n",
            "   Clean | Top-1: 19.7% | Top-5: 42.3% | Top-10: 52.7%\n",
            "   Soft  | Top-1: 19.7% | Top-5: 43.0% | Top-10: 53.1%\n",
            "   Hard  | Top-1: 4.4% | Top-5: 13.9% | Top-10: 21.9%\n",
            "   Ultra | Top-1: 5.2% | Top-5: 17.1% | Top-10: 27.4%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: MULTITASK_CRNN_Smooth.pth\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:57<00:00,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for MULTITASK_CRNN_Smooth.pth (Total Trials: 900)\n",
            "   Clean | Top-1: 17.2% | Top-5: 38.9% | Top-10: 49.7%\n",
            "   Soft  | Top-1: 16.2% | Top-5: 39.0% | Top-10: 50.1%\n",
            "   Hard  | Top-1: 4.9% | Top-5: 14.4% | Top-10: 23.6%\n",
            "   Ultra | Top-1: 5.0% | Top-5: 16.9% | Top-10: 25.7%\n",
            "\n",
            "‚úÖ DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "============================================================\n",
        "üß™ TESTING: MULTITASK_DeepCNN_Smooth.pth\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:47<00:00,  6.27it/s]\n",
        "\n",
        "üìä RESULTS for MULTITASK_DeepCNN_Smooth.pth (Total Trials: 900)\n",
        "   Clean | Top-1: 19.7% | Top-5: 42.3% | Top-10: 52.7%\n",
        "   Soft  | Top-1: 19.7% | Top-5: 43.0% | Top-10: 53.1%\n",
        "   Hard  | Top-1: 4.4% | Top-5: 13.9% | Top-10: 21.9%\n",
        "   Ultra | Top-1: 5.2% | Top-5: 17.1% | Top-10: 27.4%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: MULTITASK_CRNN_Smooth.pth\n",
        "============================================================\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:57<00:00,  5.20it/s]\n",
        "üìä RESULTS for MULTITASK_CRNN_Smooth.pth (Total Trials: 900)\n",
        "   Clean | Top-1: 17.2% | Top-5: 38.9% | Top-10: 49.7%\n",
        "   Soft  | Top-1: 16.2% | Top-5: 39.0% | Top-10: 50.1%\n",
        "   Hard  | Top-1: 4.9% | Top-5: 14.4% | Top-10: 23.6%\n",
        "   Ultra | Top-1: 5.0% | Top-5: 16.9% | Top-10: 25.7%\n"
      ],
      "metadata": {
        "id": "DxNKLrOP2Qtc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FsTvU-4VZ7Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING A MODEL FROM BASE UP"
      ],
      "metadata": {
        "id": "CAKOFjZ029Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FULL RETRAIN (DUAL ITERATION + ADAPTIVE LR SCHEDULER)\n",
        "# ==============================================================================\n",
        "\n",
        "def train_from_scratch(model_name, ModelClass):\n",
        "    print(f\"\\nüöÄ Training From Scratch (Dual Iter): {model_name}\")\n",
        "    # Higher starting LR (0.001) is essential for random weights\n",
        "    print(f\"   Configs: Epochs={EPOCHS} | Start LR=0.001 | Patience=5\")\n",
        "\n",
        "    # 1. Initialize Fresh Model\n",
        "    model = ModelClass(embed_dim=128).to(DEVICE)\n",
        "\n",
        "    # 2. Setup\n",
        "    dataset = PitchDataset(PITCH_DIR)\n",
        "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "\n",
        "    # Optimizer (Per-parameter adaptive learning)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Scheduler (Global adaptation based on loss plateau)\n",
        "    # factor=0.5 means it cuts LR in half when it gets stuck\n",
        "    # patience=5 is your requested tolerance\n",
        "    scheduler = ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "    loss_fn = nn.TripletMarginLoss(margin=0.85, p=2)\n",
        "\n",
        "    # 3. Loop\n",
        "    model.train()\n",
        "    best_loss = float('inf')\n",
        "    save_path = os.path.join(SAVE_DIR, f\"RETRAINED_{model_name}.pth\")\n",
        "\n",
        "    for ep in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for batch in loader:\n",
        "            a, p_hard, p_soft, n = [t.to(DEVICE) for t in batch]\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "            # --- FORWARD PASS (Batch Stacking for 30% Speedup) ---\n",
        "            combined_input = torch.cat([a, p_hard, p_soft, n], dim=0)\n",
        "            combined_emb = model.forward_one(combined_input)\n",
        "\n",
        "            bs = a.size(0)\n",
        "            a_emb = combined_emb[0:bs]\n",
        "            ph_emb = combined_emb[bs:2*bs]\n",
        "            ps_emb = combined_emb[2*bs:3*bs]\n",
        "            n_emb = combined_emb[3*bs:]\n",
        "\n",
        "            # --- DUAL LOSS CALCULATION ---\n",
        "            # 1. Temporal/Hard Loss (Melody Structure)\n",
        "            loss_structure = loss_fn(a_emb, ph_emb, n_emb)\n",
        "            # 2. Stability/Soft Loss (Signal Robustness)\n",
        "            loss_stability = loss_fn(a_emb, ps_emb, n_emb)\n",
        "\n",
        "            total_batch_loss = loss_structure + loss_stability\n",
        "            total_batch_loss.backward()\n",
        "\n",
        "            # Gradient Clipping (Safety for scratch training)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optim.step()\n",
        "            total_loss += (total_batch_loss.item() / 2.0)\n",
        "\n",
        "        avg_loss = total_loss / len(loader)\n",
        "\n",
        "        # --- ADAPTIVE LR STEP ---\n",
        "        # The scheduler checks if avg_loss has improved\n",
        "        scheduler.step(avg_loss)\n",
        "\n",
        "        # Get the current LR to print (from any param group)\n",
        "        current_lr = optim.param_groups[0]['lr']\n",
        "\n",
        "        print(f\"   Epoch {ep+1}/{EPOCHS} | Avg Loss: {avg_loss:.4f} | LR: {current_lr:.6f}\")\n",
        "\n",
        "        # Save Best Checkpoint\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            # print(f\"   ‚≠ê New Best Loss! Model Saved.\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Finished. Best Loss: {best_loss:.4f}\")\n",
        "    print(f\"   Final Model: {save_path}\")\n",
        "\n",
        "# --- EXECUTE ---\n",
        "train_from_scratch(\"DeepCNN_Full_Dual\", DeepCNN)\n",
        "train_from_scratch(\"CRNN_Full_Dual\", CRNN)"
      ],
      "metadata": {
        "id": "vH_NQx8IZ7ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221affad-6fc9-4ef8-da9e-665c29b00370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Training From Scratch (Dual Iter): DeepCNN_Full_Dual\n",
            "   Configs: Epochs=100 | Start LR=0.001 | Patience=5\n",
            "   Epoch 1/100 | Avg Loss: 0.3486 | LR: 0.001000\n",
            "   Epoch 2/100 | Avg Loss: 0.3317 | LR: 0.001000\n",
            "   Epoch 3/100 | Avg Loss: 0.3304 | LR: 0.001000\n",
            "   Epoch 4/100 | Avg Loss: 0.3258 | LR: 0.001000\n",
            "   Epoch 5/100 | Avg Loss: 0.3252 | LR: 0.001000\n",
            "   Epoch 6/100 | Avg Loss: 0.3144 | LR: 0.001000\n",
            "   Epoch 7/100 | Avg Loss: 0.3163 | LR: 0.001000\n",
            "   Epoch 8/100 | Avg Loss: 0.3086 | LR: 0.001000\n",
            "   Epoch 9/100 | Avg Loss: 0.3103 | LR: 0.001000\n",
            "   Epoch 10/100 | Avg Loss: 0.3116 | LR: 0.001000\n",
            "   Epoch 11/100 | Avg Loss: 0.3075 | LR: 0.001000\n",
            "   Epoch 12/100 | Avg Loss: 0.3044 | LR: 0.001000\n",
            "   Epoch 13/100 | Avg Loss: 0.2965 | LR: 0.001000\n",
            "   Epoch 14/100 | Avg Loss: 0.2948 | LR: 0.001000\n",
            "   Epoch 15/100 | Avg Loss: 0.3042 | LR: 0.001000\n",
            "   Epoch 16/100 | Avg Loss: 0.2985 | LR: 0.001000\n",
            "   Epoch 17/100 | Avg Loss: 0.2940 | LR: 0.001000\n",
            "   Epoch 18/100 | Avg Loss: 0.2968 | LR: 0.001000\n",
            "   Epoch 19/100 | Avg Loss: 0.2895 | LR: 0.001000\n",
            "   Epoch 20/100 | Avg Loss: 0.2917 | LR: 0.001000\n",
            "   Epoch 21/100 | Avg Loss: 0.3009 | LR: 0.001000\n",
            "   Epoch 22/100 | Avg Loss: 0.2961 | LR: 0.001000\n",
            "   Epoch 23/100 | Avg Loss: 0.3017 | LR: 0.001000\n",
            "   Epoch 24/100 | Avg Loss: 0.2895 | LR: 0.001000\n",
            "   Epoch 25/100 | Avg Loss: 0.2930 | LR: 0.001000\n",
            "   Epoch 26/100 | Avg Loss: 0.2968 | LR: 0.001000\n",
            "   Epoch 27/100 | Avg Loss: 0.2963 | LR: 0.001000\n",
            "   Epoch 28/100 | Avg Loss: 0.2981 | LR: 0.001000\n",
            "   Epoch 29/100 | Avg Loss: 0.2983 | LR: 0.001000\n",
            "   Epoch 30/100 | Avg Loss: 0.2956 | LR: 0.000500\n",
            "   Epoch 31/100 | Avg Loss: 0.2905 | LR: 0.000500\n",
            "   Epoch 32/100 | Avg Loss: 0.2873 | LR: 0.000500\n",
            "   Epoch 33/100 | Avg Loss: 0.2896 | LR: 0.000500\n",
            "   Epoch 34/100 | Avg Loss: 0.2872 | LR: 0.000500\n",
            "   Epoch 35/100 | Avg Loss: 0.2898 | LR: 0.000500\n",
            "   Epoch 36/100 | Avg Loss: 0.2833 | LR: 0.000500\n",
            "   Epoch 37/100 | Avg Loss: 0.2830 | LR: 0.000500\n",
            "   Epoch 38/100 | Avg Loss: 0.2855 | LR: 0.000500\n",
            "   Epoch 39/100 | Avg Loss: 0.2904 | LR: 0.000500\n",
            "   Epoch 40/100 | Avg Loss: 0.2827 | LR: 0.000500\n",
            "   Epoch 41/100 | Avg Loss: 0.2817 | LR: 0.000500\n",
            "   Epoch 42/100 | Avg Loss: 0.2884 | LR: 0.000500\n",
            "   Epoch 43/100 | Avg Loss: 0.2835 | LR: 0.000500\n",
            "   Epoch 44/100 | Avg Loss: 0.2854 | LR: 0.000500\n",
            "   Epoch 45/100 | Avg Loss: 0.2879 | LR: 0.000500\n",
            "   Epoch 46/100 | Avg Loss: 0.2812 | LR: 0.000500\n",
            "   Epoch 47/100 | Avg Loss: 0.2846 | LR: 0.000500\n",
            "   Epoch 48/100 | Avg Loss: 0.2862 | LR: 0.000500\n",
            "   Epoch 49/100 | Avg Loss: 0.2871 | LR: 0.000500\n",
            "   Epoch 50/100 | Avg Loss: 0.2864 | LR: 0.000500\n",
            "   Epoch 51/100 | Avg Loss: 0.2889 | LR: 0.000500\n",
            "   Epoch 52/100 | Avg Loss: 0.2856 | LR: 0.000250\n",
            "   Epoch 53/100 | Avg Loss: 0.2800 | LR: 0.000250\n",
            "   Epoch 54/100 | Avg Loss: 0.2823 | LR: 0.000250\n",
            "   Epoch 55/100 | Avg Loss: 0.2820 | LR: 0.000250\n",
            "   Epoch 56/100 | Avg Loss: 0.2817 | LR: 0.000250\n",
            "   Epoch 57/100 | Avg Loss: 0.2810 | LR: 0.000250\n",
            "   Epoch 58/100 | Avg Loss: 0.2806 | LR: 0.000250\n",
            "   Epoch 59/100 | Avg Loss: 0.2826 | LR: 0.000125\n",
            "   Epoch 60/100 | Avg Loss: 0.2777 | LR: 0.000125\n",
            "   Epoch 61/100 | Avg Loss: 0.2817 | LR: 0.000125\n",
            "   Epoch 62/100 | Avg Loss: 0.2821 | LR: 0.000125\n",
            "   Epoch 63/100 | Avg Loss: 0.2830 | LR: 0.000125\n",
            "   Epoch 64/100 | Avg Loss: 0.2814 | LR: 0.000125\n",
            "   Epoch 65/100 | Avg Loss: 0.2841 | LR: 0.000125\n",
            "   Epoch 66/100 | Avg Loss: 0.2782 | LR: 0.000063\n",
            "   Epoch 67/100 | Avg Loss: 0.2758 | LR: 0.000063\n",
            "   Epoch 68/100 | Avg Loss: 0.2841 | LR: 0.000063\n",
            "   Epoch 69/100 | Avg Loss: 0.2815 | LR: 0.000063\n",
            "   Epoch 70/100 | Avg Loss: 0.2805 | LR: 0.000063\n",
            "   Epoch 71/100 | Avg Loss: 0.2767 | LR: 0.000063\n",
            "   Epoch 72/100 | Avg Loss: 0.2811 | LR: 0.000063\n",
            "   Epoch 73/100 | Avg Loss: 0.2901 | LR: 0.000031\n",
            "   Epoch 74/100 | Avg Loss: 0.2796 | LR: 0.000031\n",
            "   Epoch 75/100 | Avg Loss: 0.2831 | LR: 0.000031\n",
            "   Epoch 76/100 | Avg Loss: 0.2707 | LR: 0.000031\n",
            "   Epoch 77/100 | Avg Loss: 0.2793 | LR: 0.000031\n",
            "   Epoch 78/100 | Avg Loss: 0.2800 | LR: 0.000031\n",
            "   Epoch 79/100 | Avg Loss: 0.2796 | LR: 0.000031\n",
            "   Epoch 80/100 | Avg Loss: 0.2802 | LR: 0.000031\n",
            "   Epoch 81/100 | Avg Loss: 0.2780 | LR: 0.000031\n",
            "   Epoch 82/100 | Avg Loss: 0.2823 | LR: 0.000016\n",
            "   Epoch 83/100 | Avg Loss: 0.2801 | LR: 0.000016\n",
            "   Epoch 84/100 | Avg Loss: 0.2796 | LR: 0.000016\n",
            "   Epoch 85/100 | Avg Loss: 0.2724 | LR: 0.000016\n",
            "   Epoch 86/100 | Avg Loss: 0.2824 | LR: 0.000016\n",
            "   Epoch 87/100 | Avg Loss: 0.2805 | LR: 0.000016\n",
            "   Epoch 88/100 | Avg Loss: 0.2811 | LR: 0.000008\n",
            "   Epoch 89/100 | Avg Loss: 0.2783 | LR: 0.000008\n",
            "   Epoch 90/100 | Avg Loss: 0.2763 | LR: 0.000008\n",
            "   Epoch 91/100 | Avg Loss: 0.2794 | LR: 0.000008\n",
            "   Epoch 92/100 | Avg Loss: 0.2794 | LR: 0.000008\n",
            "   Epoch 93/100 | Avg Loss: 0.2786 | LR: 0.000008\n",
            "   Epoch 94/100 | Avg Loss: 0.2778 | LR: 0.000004\n",
            "   Epoch 95/100 | Avg Loss: 0.2754 | LR: 0.000004\n",
            "   Epoch 96/100 | Avg Loss: 0.2739 | LR: 0.000004\n",
            "   Epoch 97/100 | Avg Loss: 0.2760 | LR: 0.000004\n",
            "   Epoch 98/100 | Avg Loss: 0.2730 | LR: 0.000004\n",
            "   Epoch 99/100 | Avg Loss: 0.2830 | LR: 0.000004\n",
            "   Epoch 100/100 | Avg Loss: 0.2777 | LR: 0.000002\n",
            "\n",
            "‚úÖ Finished. Best Loss: 0.2707\n",
            "   Final Model: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/retrained_models/RETRAINED_DeepCNN_Full_Dual.pth\n",
            "\n",
            "üöÄ Training From Scratch (Dual Iter): CRNN_Full_Dual\n",
            "   Configs: Epochs=100 | Start LR=0.001 | Patience=5\n",
            "   Epoch 1/100 | Avg Loss: 0.3753 | LR: 0.001000\n",
            "   Epoch 2/100 | Avg Loss: 0.3460 | LR: 0.001000\n",
            "   Epoch 3/100 | Avg Loss: 0.3563 | LR: 0.001000\n",
            "   Epoch 4/100 | Avg Loss: 0.3276 | LR: 0.001000\n",
            "   Epoch 5/100 | Avg Loss: 0.3263 | LR: 0.001000\n",
            "   Epoch 6/100 | Avg Loss: 0.3255 | LR: 0.001000\n",
            "   Epoch 7/100 | Avg Loss: 0.3267 | LR: 0.001000\n",
            "   Epoch 8/100 | Avg Loss: 0.3191 | LR: 0.001000\n",
            "   Epoch 9/100 | Avg Loss: 0.3258 | LR: 0.001000\n",
            "   Epoch 10/100 | Avg Loss: 0.3147 | LR: 0.001000\n",
            "   Epoch 11/100 | Avg Loss: 0.3177 | LR: 0.001000\n",
            "   Epoch 12/100 | Avg Loss: 0.3218 | LR: 0.001000\n",
            "   Epoch 13/100 | Avg Loss: 0.3166 | LR: 0.001000\n",
            "   Epoch 14/100 | Avg Loss: 0.3031 | LR: 0.001000\n",
            "   Epoch 15/100 | Avg Loss: 0.3216 | LR: 0.001000\n",
            "   Epoch 16/100 | Avg Loss: 0.3149 | LR: 0.001000\n",
            "   Epoch 17/100 | Avg Loss: 0.3153 | LR: 0.001000\n",
            "   Epoch 18/100 | Avg Loss: 0.3033 | LR: 0.001000\n",
            "   Epoch 19/100 | Avg Loss: 0.2995 | LR: 0.001000\n",
            "   Epoch 20/100 | Avg Loss: 0.3030 | LR: 0.001000\n",
            "   Epoch 21/100 | Avg Loss: 0.3003 | LR: 0.001000\n",
            "   Epoch 22/100 | Avg Loss: 0.2968 | LR: 0.001000\n",
            "   Epoch 23/100 | Avg Loss: 0.3016 | LR: 0.001000\n",
            "   Epoch 24/100 | Avg Loss: 0.2957 | LR: 0.001000\n",
            "   Epoch 25/100 | Avg Loss: 0.3047 | LR: 0.001000\n",
            "   Epoch 26/100 | Avg Loss: 0.3012 | LR: 0.001000\n",
            "   Epoch 27/100 | Avg Loss: 0.2998 | LR: 0.001000\n",
            "   Epoch 28/100 | Avg Loss: 0.3002 | LR: 0.001000\n",
            "   Epoch 29/100 | Avg Loss: 0.2930 | LR: 0.001000\n",
            "   Epoch 30/100 | Avg Loss: 0.3026 | LR: 0.001000\n",
            "   Epoch 31/100 | Avg Loss: 0.2970 | LR: 0.001000\n",
            "   Epoch 32/100 | Avg Loss: 0.2933 | LR: 0.001000\n",
            "   Epoch 33/100 | Avg Loss: 0.3007 | LR: 0.001000\n",
            "   Epoch 34/100 | Avg Loss: 0.2995 | LR: 0.001000\n",
            "   Epoch 35/100 | Avg Loss: 0.3076 | LR: 0.000500\n",
            "   Epoch 36/100 | Avg Loss: 0.3017 | LR: 0.000500\n",
            "   Epoch 37/100 | Avg Loss: 0.2928 | LR: 0.000500\n",
            "   Epoch 38/100 | Avg Loss: 0.2820 | LR: 0.000500\n",
            "   Epoch 39/100 | Avg Loss: 0.2935 | LR: 0.000500\n",
            "   Epoch 40/100 | Avg Loss: 0.2884 | LR: 0.000500\n",
            "   Epoch 41/100 | Avg Loss: 0.2910 | LR: 0.000500\n",
            "   Epoch 42/100 | Avg Loss: 0.2891 | LR: 0.000500\n",
            "   Epoch 43/100 | Avg Loss: 0.2961 | LR: 0.000500\n",
            "   Epoch 44/100 | Avg Loss: 0.2922 | LR: 0.000250\n",
            "   Epoch 45/100 | Avg Loss: 0.2861 | LR: 0.000250\n",
            "   Epoch 46/100 | Avg Loss: 0.2949 | LR: 0.000250\n",
            "   Epoch 47/100 | Avg Loss: 0.2844 | LR: 0.000250\n",
            "   Epoch 48/100 | Avg Loss: 0.2771 | LR: 0.000250\n",
            "   Epoch 49/100 | Avg Loss: 0.2870 | LR: 0.000250\n",
            "   Epoch 50/100 | Avg Loss: 0.2863 | LR: 0.000250\n",
            "   Epoch 51/100 | Avg Loss: 0.2876 | LR: 0.000250\n",
            "   Epoch 52/100 | Avg Loss: 0.2867 | LR: 0.000250\n",
            "   Epoch 53/100 | Avg Loss: 0.2803 | LR: 0.000250\n",
            "   Epoch 54/100 | Avg Loss: 0.2893 | LR: 0.000125\n",
            "   Epoch 55/100 | Avg Loss: 0.2895 | LR: 0.000125\n",
            "   Epoch 56/100 | Avg Loss: 0.2810 | LR: 0.000125\n",
            "   Epoch 57/100 | Avg Loss: 0.2865 | LR: 0.000125\n",
            "   Epoch 58/100 | Avg Loss: 0.2813 | LR: 0.000125\n",
            "   Epoch 59/100 | Avg Loss: 0.2844 | LR: 0.000125\n",
            "   Epoch 60/100 | Avg Loss: 0.2848 | LR: 0.000063\n",
            "   Epoch 61/100 | Avg Loss: 0.2832 | LR: 0.000063\n",
            "   Epoch 62/100 | Avg Loss: 0.2904 | LR: 0.000063\n",
            "   Epoch 63/100 | Avg Loss: 0.2818 | LR: 0.000063\n",
            "   Epoch 64/100 | Avg Loss: 0.2795 | LR: 0.000063\n",
            "   Epoch 65/100 | Avg Loss: 0.2839 | LR: 0.000063\n",
            "   Epoch 66/100 | Avg Loss: 0.2855 | LR: 0.000031\n",
            "   Epoch 67/100 | Avg Loss: 0.2836 | LR: 0.000031\n",
            "   Epoch 68/100 | Avg Loss: 0.2799 | LR: 0.000031\n",
            "   Epoch 69/100 | Avg Loss: 0.2815 | LR: 0.000031\n",
            "   Epoch 70/100 | Avg Loss: 0.2885 | LR: 0.000031\n",
            "   Epoch 71/100 | Avg Loss: 0.2833 | LR: 0.000031\n",
            "   Epoch 72/100 | Avg Loss: 0.2857 | LR: 0.000016\n",
            "   Epoch 73/100 | Avg Loss: 0.2852 | LR: 0.000016\n",
            "   Epoch 74/100 | Avg Loss: 0.2827 | LR: 0.000016\n",
            "   Epoch 75/100 | Avg Loss: 0.2877 | LR: 0.000016\n",
            "   Epoch 76/100 | Avg Loss: 0.2800 | LR: 0.000016\n",
            "   Epoch 77/100 | Avg Loss: 0.2815 | LR: 0.000016\n",
            "   Epoch 78/100 | Avg Loss: 0.2791 | LR: 0.000008\n",
            "   Epoch 79/100 | Avg Loss: 0.2843 | LR: 0.000008\n",
            "   Epoch 80/100 | Avg Loss: 0.2829 | LR: 0.000008\n",
            "   Epoch 81/100 | Avg Loss: 0.2893 | LR: 0.000008\n",
            "   Epoch 82/100 | Avg Loss: 0.2813 | LR: 0.000008\n",
            "   Epoch 83/100 | Avg Loss: 0.2878 | LR: 0.000008\n",
            "   Epoch 84/100 | Avg Loss: 0.2805 | LR: 0.000004\n",
            "   Epoch 85/100 | Avg Loss: 0.2869 | LR: 0.000004\n",
            "   Epoch 86/100 | Avg Loss: 0.2824 | LR: 0.000004\n",
            "   Epoch 87/100 | Avg Loss: 0.2843 | LR: 0.000004\n",
            "   Epoch 88/100 | Avg Loss: 0.2847 | LR: 0.000004\n",
            "   Epoch 89/100 | Avg Loss: 0.2829 | LR: 0.000004\n",
            "   Epoch 90/100 | Avg Loss: 0.2813 | LR: 0.000002\n",
            "   Epoch 91/100 | Avg Loss: 0.2914 | LR: 0.000002\n",
            "   Epoch 92/100 | Avg Loss: 0.2934 | LR: 0.000002\n",
            "   Epoch 93/100 | Avg Loss: 0.2829 | LR: 0.000002\n",
            "   Epoch 94/100 | Avg Loss: 0.2816 | LR: 0.000002\n",
            "   Epoch 95/100 | Avg Loss: 0.2812 | LR: 0.000002\n",
            "   Epoch 96/100 | Avg Loss: 0.2801 | LR: 0.000001\n",
            "   Epoch 97/100 | Avg Loss: 0.2833 | LR: 0.000001\n",
            "   Epoch 98/100 | Avg Loss: 0.2762 | LR: 0.000001\n",
            "   Epoch 99/100 | Avg Loss: 0.2854 | LR: 0.000001\n",
            "   Epoch 100/100 | Avg Loss: 0.2856 | LR: 0.000001\n",
            "\n",
            "‚úÖ Finished. Best Loss: 0.2762\n",
            "   Final Model: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/retrained_models/RETRAINED_CRNN_Full_Dual.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 6. EVALUATION OF RETRAINED MODELS\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import scipy.signal as sg\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIG ---\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Data: The Giant Expanded Dataset (3000+ Songs)\n",
        "PITCH_DIR = \"/content/expanded_pitch\"\n",
        "\n",
        "# Models: Point to your new retrained models\n",
        "MODEL_DIR = \"/content/drive/MyDrive/FIND_TUNE/pitch_based_model/retrained_models\"\n",
        "\n",
        "# --- ARCHITECTURES (Must match training exactly) ---\n",
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 32, 5, padding=2), nn.BatchNorm1d(32), nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
        "    def forward_one(self, x): return F.normalize(self.fc(self.cnn(x).squeeze(-1)), p=2, dim=1)\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(1, 64, 5, padding=2), nn.BatchNorm1d(64), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64, 128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(256, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.Linear(256, 256), nn.ReLU(), nn.Linear(256, embed_dim))\n",
        "    def forward_one(self, x):\n",
        "        x = self.cnn(x).permute(0, 2, 1)\n",
        "        self.lstm.flatten_parameters()\n",
        "        out, _ = self.lstm(x)\n",
        "        return F.normalize(self.fc(torch.mean(out, dim=1)), p=2, dim=1)\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "def smooth_pitch(pitch):\n",
        "    return sg.medfilt(pitch, kernel_size=5).astype(np.float32)\n",
        "\n",
        "def augment_clip(arr, mode='clean'):\n",
        "    arr = arr.copy()\n",
        "    if mode == 'clean': return arr\n",
        "\n",
        "    elif mode == 'soft': # Light Noise\n",
        "        return arr + np.random.normal(0, 0.02, size=len(arr))\n",
        "\n",
        "    elif mode == 'hard': # Noise + Key Shift + Time Warp (Standard)\n",
        "        arr += np.random.normal(0, 0.06, size=len(arr))\n",
        "        arr[arr > 0] += np.random.uniform(-3, 3) * 0.057\n",
        "        if random.random() < 0.8: # Warp\n",
        "            rate = np.random.uniform(0.85, 1.15)\n",
        "            new_idx = np.linspace(0, len(arr)-1, int(len(arr)*rate))\n",
        "            arr = np.interp(new_idx, np.arange(len(arr)), arr)\n",
        "            if len(arr) < 300: arr = np.pad(arr, (0, 300-len(arr)), 'constant')\n",
        "            else: arr = arr[:300]\n",
        "        return arr\n",
        "\n",
        "    elif mode == 'ultra': # The Stress Test (Drift + Dropout)\n",
        "        arr += np.random.normal(0, 0.1, size=len(arr))\n",
        "        # Cumulative drift (tempo drift)\n",
        "        rate = np.cumsum(np.linspace(0.8, 1.2, len(arr)))\n",
        "        rate = rate / rate[-1] * (len(arr)-1)\n",
        "        arr = np.interp(np.arange(len(arr)), rate, arr)\n",
        "        return arr\n",
        "    return arr\n",
        "\n",
        "def build_db_for_model(model, pitch_dir):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    db_embeds = []\n",
        "    metadata = []\n",
        "\n",
        "    model.eval()\n",
        "    print(f\"   Building Database from {len(files)} files...\")\n",
        "    with torch.no_grad():\n",
        "        for f in tqdm(files, desc=\"Indexing DB\", leave=False):\n",
        "            arr = np.load(f)\n",
        "            arr = smooth_pitch(arr) # Always smooth DB tracks\n",
        "\n",
        "            # Windowing (3s windows, 1.5s hop)\n",
        "            windows = []\n",
        "            offsets = []\n",
        "            i = 0\n",
        "            while i + 300 <= len(arr):\n",
        "                crop = arr[i:i+300]\n",
        "                if np.mean(crop > 0) > 0.1: # Skip silence\n",
        "                    windows.append(crop)\n",
        "                    offsets.append(i/100.0)\n",
        "                i += 150\n",
        "\n",
        "            if not windows: continue\n",
        "\n",
        "            # Batch Inference\n",
        "            w_tensor = torch.from_numpy(np.stack(windows)).float().unsqueeze(1).to(DEVICE)\n",
        "            # Batch processing to avoid OOM on huge files\n",
        "            batch_size = 512\n",
        "            for k in range(0, len(w_tensor), batch_size):\n",
        "                batch = w_tensor[k:k+batch_size]\n",
        "                embeddings = model.forward_one(batch)\n",
        "                db_embeds.append(embeddings)\n",
        "\n",
        "            song_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "            for t in offsets:\n",
        "                metadata.append((song_name, t))\n",
        "\n",
        "    if not db_embeds: return None, None\n",
        "    return torch.cat(db_embeds), metadata\n",
        "\n",
        "def run_evaluation(model, db_tensor, db_meta, pitch_dir):\n",
        "    files = sorted(glob.glob(os.path.join(pitch_dir, \"*.npy\")))\n",
        "    # Pick random subset of 300 songs for evaluation speed\n",
        "    # (Checking all 3000+ takes too long, 300 is statistically significant)\n",
        "    if len(files) > 300:\n",
        "        random.shuffle(files)\n",
        "        files = files[:300]\n",
        "\n",
        "    modes = ['Clean', 'Soft', 'Hard', 'Ultra']\n",
        "    results = {m: {'top1':0, 'top5':0, 'top10':0} for m in modes}\n",
        "    total_clips = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for f in tqdm(files, desc=\"Eval Loop\"):\n",
        "        full_arr = np.load(f)\n",
        "        if len(full_arr) < 500: continue\n",
        "        target_name = os.path.basename(f).replace(\".npy\",\"\")\n",
        "\n",
        "        # Take 3 random starting points per song\n",
        "        starts = np.random.randint(0, len(full_arr)-300, 3)\n",
        "\n",
        "        for s in starts:\n",
        "            base_clip = full_arr[s:s+300]\n",
        "            base_clip = smooth_pitch(base_clip) # Always smooth query\n",
        "\n",
        "            total_clips += 1\n",
        "\n",
        "            for mode in modes:\n",
        "                aug_clip = augment_clip(base_clip, mode=mode.lower())\n",
        "                q_tensor = torch.from_numpy(aug_clip).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    q_emb = model.forward_one(q_tensor)\n",
        "\n",
        "                # Geometric Scoring\n",
        "                dists = torch.cdist(q_emb, db_tensor)\n",
        "                vals, inds = torch.topk(dists, k=50, largest=False)\n",
        "\n",
        "                votes = defaultdict(float)\n",
        "                for k in range(50):\n",
        "                    idx = inds[0, k].item()\n",
        "                    dist = vals[0, k].item()\n",
        "                    m_name, m_time = db_meta[idx]\n",
        "                    score = 1.0 / (dist + 1e-4)\n",
        "                    votes[m_name] += score\n",
        "\n",
        "                ranked = sorted(votes.items(), key=lambda x: x[1], reverse=True)\n",
        "                top_names = [x[0] for x in ranked]\n",
        "\n",
        "                if not top_names: continue\n",
        "\n",
        "                if top_names[0] == target_name: results[mode]['top1'] += 1\n",
        "                if target_name in top_names[:5]: results[mode]['top5'] += 1\n",
        "                if target_name in top_names[:10]: results[mode]['top10'] += 1\n",
        "\n",
        "    return results, total_clips\n",
        "\n",
        "# ==============================================================================\n",
        "# MASTER LOOP (RETRAINED MODELS)\n",
        "# ==============================================================================\n",
        "# Note: These names match the save logic in the training script\n",
        "experiments = [\n",
        "    (\"RETRAINED_DeepCNN_Full_Dual.pth\", DeepCNN),\n",
        "    (\"RETRAINED_CRNN_Full_Dual.pth\",    CRNN),\n",
        "]\n",
        "\n",
        "print(f\"üöÄ STARTING RETRAINED MODEL EVALUATION\")\n",
        "print(f\"üìÇ Pitch Dir: {PITCH_DIR}\")\n",
        "print(f\"üìÇ Model Dir: {MODEL_DIR}\")\n",
        "\n",
        "for model_name, ModelClass in experiments:\n",
        "    model_path = os.path.join(MODEL_DIR, model_name)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"\\n‚ö†Ô∏è SKIPPING {model_name} (File not found)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"üß™ TESTING: {model_name}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Load\n",
        "    model = ModelClass(embed_dim=128).to(DEVICE)\n",
        "    try:\n",
        "        ckpt = torch.load(model_path, map_location=DEVICE)\n",
        "        if 'model' in ckpt: model.load_state_dict(ckpt['model'])\n",
        "        else: model.load_state_dict(ckpt)\n",
        "        print(\"   ‚úÖ Weights Loaded Successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 2. Build DB\n",
        "    db_tensor, db_meta = build_db_for_model(model, PITCH_DIR)\n",
        "    if db_tensor is None:\n",
        "        print(\"‚ùå DB Build Failed (No embeddings generated)\")\n",
        "        continue\n",
        "\n",
        "    # 3. Eval\n",
        "    res, total = run_evaluation(model, db_tensor, db_meta, PITCH_DIR)\n",
        "\n",
        "    # 4. Report\n",
        "    print(f\"\\nüìä RESULTS for {model_name} (Total Trials: {total})\")\n",
        "    for mode in ['Clean', 'Soft', 'Hard', 'Ultra']:\n",
        "        t1 = res[mode]['top1'] / total * 100\n",
        "        t5 = res[mode]['top5'] / total * 100\n",
        "        t10 = res[mode]['top10'] / total * 100\n",
        "        print(f\"   {mode:5} | Top-1: {t1:.1f}% | Top-5: {t5:.1f}% | Top-10: {t10:.1f}%\")\n",
        "\n",
        "print(\"\\n‚úÖ DONE.\")"
      ],
      "metadata": {
        "id": "na2D_1iIZ7ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71739bd9-349e-46ff-c46b-dfd3d8e1da91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ STARTING RETRAINED MODEL EVALUATION\n",
            "üìÇ Pitch Dir: /content/expanded_pitch\n",
            "üìÇ Model Dir: /content/drive/MyDrive/FIND_TUNE/pitch_based_model/retrained_models\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: RETRAINED_DeepCNN_Full_Dual.pth\n",
            "============================================================\n",
            "   ‚úÖ Weights Loaded Successfully\n",
            "   Building Database from 2944 files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:47<00:00,  6.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for RETRAINED_DeepCNN_Full_Dual.pth (Total Trials: 900)\n",
            "   Clean | Top-1: 19.0% | Top-5: 38.3% | Top-10: 50.4%\n",
            "   Soft  | Top-1: 15.9% | Top-5: 36.0% | Top-10: 49.4%\n",
            "   Hard  | Top-1: 0.6% | Top-5: 1.6% | Top-10: 2.8%\n",
            "   Ultra | Top-1: 0.1% | Top-5: 1.8% | Top-10: 2.7%\n",
            "\n",
            "============================================================\n",
            "üß™ TESTING: RETRAINED_CRNN_Full_Dual.pth\n",
            "============================================================\n",
            "   ‚úÖ Weights Loaded Successfully\n",
            "   Building Database from 2944 files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:57<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä RESULTS for RETRAINED_CRNN_Full_Dual.pth (Total Trials: 900)\n",
            "   Clean | Top-1: 11.9% | Top-5: 28.7% | Top-10: 37.7%\n",
            "   Soft  | Top-1: 11.1% | Top-5: 27.9% | Top-10: 37.4%\n",
            "   Hard  | Top-1: 0.2% | Top-5: 1.2% | Top-10: 2.9%\n",
            "   Ultra | Top-1: 0.4% | Top-5: 1.3% | Top-10: 2.6%\n",
            "\n",
            "‚úÖ DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "üìä RESULTS for RETRAINED_DeepCNN_Full_Dual.pth (Total Trials: 900)\n",
        "   Clean | Top-1: 19.0% | Top-5: 38.3% | Top-10: 50.4%\n",
        "   Soft  | Top-1: 15.9% | Top-5: 36.0% | Top-10: 49.4%\n",
        "   Hard  | Top-1: 0.6% | Top-5: 1.6% | Top-10: 2.8%\n",
        "   Ultra | Top-1: 0.1% | Top-5: 1.8% | Top-10: 2.7%\n",
        "\n",
        "============================================================\n",
        "üß™ TESTING: RETRAINED_CRNN_Full_Dual.pth\n",
        "============================================================\n",
        "   ‚úÖ Weights Loaded Successfully\n",
        "   Building Database from 2944 files...\n",
        "Eval Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [00:57<00:00,  5.22it/s]\n",
        "üìä RESULTS for RETRAINED_CRNN_Full_Dual.pth (Total Trials: 900)\n",
        "   Clean | Top-1: 11.9% | Top-5: 28.7% | Top-10: 37.7%\n",
        "   Soft  | Top-1: 11.1% | Top-5: 27.9% | Top-10: 37.4%\n",
        "   Hard  | Top-1: 0.2% | Top-5: 1.2% | Top-10: 2.9%\n",
        "   Ultra | Top-1: 0.4% | Top-5: 1.3% | Top-10: 2.6%"
      ],
      "metadata": {
        "id": "EvywKxQg8WED"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HXqhB6gqZ7bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pe92VdDZ7cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HXLxm_dZ7dM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaPfSEjGZ7eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y3-oaQGPZ7fH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FV89_bwWZ7gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2iIiLQGZ7g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "egcJCbfBZ7iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7DN-WpGVZ7jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wqMF5fB3Z7k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUUK3pwsZ7l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7erf6a3bZ7m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIwkd_d5Z7n6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}